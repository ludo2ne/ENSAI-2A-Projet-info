[
  {
    "objectID": "doc/anciens-sujets.html",
    "href": "doc/anciens-sujets.html",
    "title": "Anciens sujets",
    "section": "",
    "text": "Tuteur : Cyriel Mallart\n\n\nTu veux parler musique avec des gens qui comprennent tes goûts ? Avec (NomDeVotreWebService), c’est facile ! Enregistre-toi, dis-nous ce que tu écoutes, et on t’envoie des gens qui vibrent au même rythme que toi !\nVous allez créer dans ce projet une API qui met en relation des gens, basée sur leurs goûts musicaux. Un.e utilisateur.ice s’inscrira, sélectionnera et enregistrera ses morceaux, artistes et genres préférés. L’API Deezer vous donnera accès à toutes les caractéristiques de ces morceaux. A partir de cela, vous utiliserez une touche d’IA pour trouver celui ou celle qui a le profil le plus similaire, et lui enverrez une petite notification pour mettre tout le monde en contact. Si ça ne matche pas, ou si l’utilisateur.ice veut découvrir de nouvelles personnes, on trouve le profil similaire le plus proche en excluant les gens déjà en contact ou refusés.\n\n\n\n\ngestion de plusieurs utilisateurs\nenregistrement des morceaux, artistes, genres, etc. utiles en base de données\nappels à l’API Deezer pour obtenir les informations sur les morceaux\nobtention, stockage et mise à jour des profils similaires\ngestion des notifications de mise en contact : accepté, refusé, notification à tous les utilisateur.ices impliquée.e.s\n\n\n\n\n\nauthentification par mot de passe\ngestion des “contacts” d’un utilisateur : déletion, signalement, création de groupes\nrecommendation de nouveaux morceaux basés sur ceux des contacts\nplaylists crées par fusion des morceaux des utilisateurs, export\nsélection ergonomique des morceaux (suggestions, autocomplétion, …)\nalgorithme de recommendation plus élaboré\n…\ntout autre idée qui vous semble logique, intéressante, sous réserve qu’elle soit faisable techniquement dans les temps impartis\n\n\n\n\n\nBackend : FastAPI\nFront end : Jinja2 (templates HTML dans FastAPI). D’autres choix sont possibles (React.js, Vue.js, …) si vous les maîtrisez, mais attention, votre tuteur ne pourra vous suivre que sur React.js, et la courbe d’apprentissage est raide.\nBDD : MongoDB (NoSQL) , Neo4j (NoSQL, graphe) ou Postgres (SQL, disponible à l’ENSAI)\nAPI Deezer : https://developers.deezer.com/api\n\n\n\n\n\nCréer une appli de messagerie : le but de ce projet est uniquement une mise en contact où l’on partagera une adresse mail par exemple\nSe casser la tête sur un algorithme super-classe : les performances de l’algorithme de recommendation ne sont pas le point important ici, ne passez pas tout votre projet dessus. Si vous avez envie d’essayer une idée d’algorithme, allez-y, même si elle ne fonctionne pas bien au final. Sinon, votre tuteur pourra vous aider sur un algorithme de base\nUne interface réctive super-évoluée avec des graphiques et des previews de morceaux : on attend une interface basique et simple, c’est-à-dire, des pages HTML statique écrit en noir sur fond blanc avec un ou deux boutons.\n\n\n\n\n\nTuteur : Colin Leverger Objectif\nVous êtes un groupe d’étudiants de l’ENSAI en deuxième année, et souhaitez développer une application en ligne de commande pour faciliter vos futures recherches de stage. Votre startup s’appelle ……… et votre application ………. .\nVotre application permettra à un utilisateur de rechercher des stages de son choix sur un ou plusieurs sites de recherche de stage (Hellowork, welcometothejungle, …). Les stages peuvent être publiés dans différentes spécialités (informatique, data analyse, machine learning, …). S’il est authentifié, l’utilisateur pourra sauvegarder dans l’application les stages qui l’intéressent dans sa « liste d’envies », et pourquoi pas répondre aux offres plus facilement (automatiquement, ou au minimum récupérer les contacts vers les employeurs). La navigation et les recherches de tout utilisateur seront historisées.\nDeux types d’utilisateurs authentifiés pourront cohabiter : utilisateur « élève » et utilisateur « professeur ». Un « administrateur » de l’app pourra également gérer l’application et les utilisateurs. Un utilisateur non authentifié sera par défaut dans la catégorie « élève ». On peut imaginer que les besoins des professeurs et des élèves seront différents…\nL’application permettra aux utilisateurs authentifiés de gérer leurs comptes, préférences, mots de passe, listes, et à tous les utilisateurs d’exporter/importer leurs recherches courantes (dans le format texte que vous jugerez bon).\nLes utilisateurs pourront également géo localiser les stages par rapport à leur position actuelle (temps de trajet,…).\nFonctionnalités requises (numérotées, mais non ordonnées)\n\nF1 : la recherche de résultats sur un site que vous choisirez (Hellowork, welcometothejungle, …)\nF2 : authentification et gestion du profil utilisateur/profil administrateur\nF3 : gestion de l’import/export de données au format choisi\nF4 : gestion de l’historique des recherches\nF5 : recherche par catégorie/filtre de recherches\n\nFonctionnalités optionnelles\n\nFO1 : lancer des recherches sur plusieurs sites en parallèle\nFO2 : géo localisation de l’utilisateur et des annonces/distance entre l’utilisateur et l’annonce\nFO3 : alertes automatiques si de nouvelles annonces de stage remplissant les critères sont publiées\nFO4 : … à vous de jouer !\nNOTE : ce sujet regorge de « … ». En effet, une participation active est vivement recommandée et vos idées, pour rendre votre projet unique, sont les bienvenues !\n\nFonctionnalités non notées (et déconseillées)\n\nles statistiques/modèles complexes que vous pourrez imaginer (une moyenne, OK, mais un modèle expo logarithmique quantique d’ordre 10, non)\nl’interface graphique type GUI (AUCUN point bonus sur une très jolie interface !)\n\n\n\n\nTuteur : Maxence Lagalle\n\n\nGreenStream est une API REST qui permet de réduire l’impact carbone d’un service de VOD (Netflix, Amazon Prime, Disney+…). Pour le consommateur, elle calcule l’impact carbone d’une vidéo à partir de sa durée et de sa résolution, en utilisant le modèle “1byte” de The Shift Project ou d’autres modèles d’estimation. Pour le fournisseur de VOD, elle aide à choisir des serveurs dans la meilleure zone géographique des fournisseurs Cloud en fonction de l’impact carbone de la production d’électricité. Ces données sur l’impact carbone sont fournies par l’API ElectricityMaps. GreenStream est un projet innovant et écologique, qui accompagne dans la transition vers des services de VOD plus vert et plus responsables.\nElectricityMaps est partenaire de GreenStream et offre un accès à la version payante de son API pour toute la durée du projet.\n\n\n\n\nEstimation de l’empreinte carbone d’une vidéo selon le modèle “1byte” de The Shift Project\n\nPrise en compte de la localisation géographique du fournisseur de VOD et de l’utilisateur\nPrise en compte de la durée et de la qualité de la vidéo, du type de connexion et du matériel utilisé pour regarder la vidéo\nUtilisation des données d’impact carbone en temps réel fournies par l’API ElectricityMaps\n\nRecommandation du meilleur service Cloud pour diffuser une vidéo à un utilisateur\n\nChoix du service Cloud à l’impact carbone le plus faible en fonction de la zone géographique de l’utilisateur\nDétermination des services Cloud éligibles en fonction de la localisation de l’utilisateur (ceux dans le même pays ou un pays limitrophe)\nUtilisation des données de prévision de l’impact carbone pour la durée de la vidéo fournies par l’API ElectricityMaps\n\nGestion de l’offre des fournisseurs Cloud\n\nImplémentation de la liste des zones géographiques proposées par au moins deux fournisseurs Cloud (AWS, GCP, Azure…)\nUtilisation d’une base de données SQL pour stocker les informations sur les services Cloud disponibles\n\nInformation sur l’état du service GreenStream\n\nFourniture d’un service permettant de s’assurer que GreenStream fonctionne correctement et que son lien avec ElectricityMaps est actif\n\n\n\n\n\n\nSimulation de l’impact carbone d’un changement de comportement\n\nCréation d’un service qui permet à l’utilisateur de simuler l’impact carbone qu’il aurait s’il changeait certains paramètres de sa consommation de vidéos, tels que la qualité, la durée, le type de connexion ou le matériel utilisé\nUtilisation du modèle “1byte” ou d’autres modèles d’estimation pour calculer l’empreinte carbone selon les différents scénarios\n\nUtilisation de modèles d’estimation de l’empreinte carbone plus sophistiqués\n\nPrise en compte d’une consommation électrique variable selon les fournisseurs Cloud\nUtilisation d’autres modèles d’estimation publiés, tels que le modèle “Carbon Footprint of Video Streaming” de Carbon Trust ou d’autres modèles à rechercher\n\nIntégration de critères avancés dans la recommandation du service Cloud\n\nPrise en compte du coût financier des services Cloud et d’un arbitrage entre le coût et l’empreinte carbone\nUtilisation d’un graphe de connexions entre les zones pour déterminer la liste des services Cloud éligibles pour diffuser une vidéo à un utilisateur\n\nSuivi de la consommation totale du service et de son empreinte carbone\n\nEnregistrement SQL de la consommation de vidéos : durée, zone géographique de l’utilisateur, service Cloud associé, empreinte carbone\nAccès aux données brutes ou à une synthèse statistique via l’API\n\nFonctionnement en mode dégradé\n\nUtilisation de données historiques d’intensité carbone de la production d’électricité en cas de défaillance de l’API ElectricityMaps\n\n\nL’initiative est fortement encouragée dans ce projet, et d’autres idées de fonctionnalités avancées ou d’amélioration des fonctionnalités de base peuvent être proposées par les élèves.\n\n\n\n\nTuteur : Thierry Mathé\n\n\nLe ministère des Finances met à disposition un fichier des prix des carburants dans les stations françaises. Ce fichier au format XML contient entre autre pour chaque station, ses coordonnées, son adresse, ses heures d’ouvertures, le prix des carburants disponibles (mais l’enseigne de la station n’y figure pas). Le but du projet de créer une API (application programming interface) qui exploite les données contenues dans ce fichier. Cette API devra permettre de :\n\nConsulter la liste des stations se trouvant à proximité d’un point donné il sera aussi possible de préciser le carburant.\nCréer et mettre à jour des listes de stations qu’il sera possible de consulter par exemple pour voir les prix sur les stations se trouvant sur un trajet régulier.\n\nA chaque requête, l’API doit s’assurer qu’elle utilise bien les dernières données disponibles et au besoin télécharger les nouvelles données disponibles sur le site (mises à jour toutes les 10 minutes) : https://donnees.roulez-eco.fr/opendata/instantane\n\n\n\n\n\nLes paramètres donnés à cette requête sont les coordonnées (longitude et latitude) d’un point, une distance en km et un type de carburant. L’API va alors extraire l’ensemble des stations se trouvant dans la zone ainsi définie et disponsant du carburant indiqué.\nLa réponse sera données au format JSON et contiendra:\n\nles parmètres de la requête\nla date et l’heure d’exécution\nle nombre de stations trouvées\nla liste des stations : pour chaque station on aura:\n\nl’id, les coordonnées et l’adresse de la station\nle prix du carburant\n\n\n\n\n\nLa gestion des listes de stations doit permettre de: - Créer une liste: le paramètre en entrée est un nom donné par l’utilisateur. La requête revoie un identifiant qui devra être passé comme paramètre pour toutes les autres actions, - Consulter la liste des listes crées: aucun paramètre, la requête renvoie les couple identifiant-nom des listes défines, - Ajouter une une plusieurs stations à un liste: les paramètres en entrée sont l’identifiant de la liste et le ou les identifiants des stations à ajouter, - Supprimer une liste: le paramètre à donner est l’identifiant de la liste, - Consulter la liste: le paramètre à donner est l’identifiant de la liste. La requête revoie les informations au format JSON qui contiennent: - l’identifiant et le nom de la requête - la date et l’heure d’exécution - le nombre de stations contenues dans la liste - la liste des stations. Pour chaque station on aura: - l’id, les coordonnées et l’adresse de la station - le prix du carburant\n\n\n\n\nVoici quelques idées de fonctions avancées pour les groupes qui auraient effectué l’ensemble des fonction de bases. Toutes autres idées pourra bien sûr être proposées en cours de projet. ##### Stations à proximités\n\nPossibilité de passer comme parmètre une adresse au lieu de coordonnées\nPossibilité de préciser l’heure de passage et de ne conserver que les stations ouvertes à cette heure.\n\n\n\n\nPossilité de retirer une ou plusieur stations d’une liste\nImposer une identification pour consulter les listes. Chaque utilisateurs n’aurait alors accés qu’à ses liste.\n\n\n\n\n\n\nTuteur : Aloïs DE OLIVEIRA\n\n\nLeague Of Legends (connu sous le sigle LoL) est un jeu video, plus précisément un Multiplayer Online Battle Arena (MOBA), développé par Riot. LoL comptait plus de 100M de joueurs actifs en 2022 et le chiffre n’est pas voué à diminuer dans les prochaines années. Cet engouement force Riot à se renouveler en créant de nouveaux champions, de nouveaux items, des ajustements sur l’équilibrage du jeu (appelés patch). Les joueurs apprécient donc fortement les outils leur permettant d’avoir des analyses simples mais rapides afin de les accompagner et aider dans leurs choix.\nCe sujet ne nécessite pas de connaître le jeu ou d’y avoir déjà joué. Au contraire, il vous arrivera souvent de devoir dans un premier temps comprendre un nouveau contexte métier et vos données en entrée.\n\n\n\n\n\nVous êtes mobilisés afin de mettre en place une solution capable de fournir aux joueurs les premières informations essentielles. Ces analyses seront simples mais nécessiteront d’analyser tout l’historique des parties que vous aurez à votre disposition, et donc que vous stockerez. Votre solution a pour but d’être pensée dans une logique d’amélioration continue. Ainsi un code documenté utilisant les principes de la Programmation Orientée Objet (POO) est attendu.\n\n\n\nLoL met à disposition une API afin de permettre aux personnes qui le souhaitent de pouvoir utiliser leurs données. Une explication du fonctionnement de l’API de LoL et de l’obtention des données sera effectuée.\n\n\n\n\nLors de ce projet, vous aurez des fonctionnalités obligatoires et avancées. Il est nécessaire de se focaliser sur ces premières et d’entreprendre les secondes que lorsque vous avez une base solide pour répondre à l’ensemble des fonctionnalités obligatoires.\n\n\n\nNiveau base de données\n\n\n\nCréation d’une base de données de votre choix (SQL/NoSQL) qui vous servira à stocker l’historique des parties. Le modèle de données est important, il doit être adapté afin de faciliter toutes modifications.\nCréation d’un pipeline de données. L’ensemble des étapes de la collecte au chargement, en passant par la transformation doivent être le plus réutilisable possible.\nL’ensemble des tâches doit être effectué en Python (de la création, à l’insertion et aux éventuelles modifications).\n\nNiveau API\nPour la réalisation de ce projet, vous devrez réaliser une API (à l’aide FastAPI ou Flask) qui vous permettra de renvoyer les différents résultats souhaités. Ces résultats seront à retourner sous format json. Il existera différentes classes, décrites ci-dessous, avec chacune ses méthodes. Toutes les méthodes présentes dans les descriptions des classes sont à titre indicatif. N’hésitez pas à être force de proposition.\n\n\n\n\nCela ne nécessitera aucune connexion.\nCette classe devra comporter certaines méthodes permettant de fournir des statistiques globales sur le jeu, telles que :\n\nAfficher les statistiques d’un champion : le nombre de games jouées, le winrate, le gold lead à Xmin, etc.\nTrier les champions (globalement ou par lane) selon le critère au choix parmi : nombre de games jouées, le winrate, etc.\n\n\n\n\n\n\nCela nécessitera de se connecter à un compte user.\nCette classe héritera de l’ensemble des méthodes propres à la classe invité.\nCette classe devra comporter certaines méthodes permettant de fournir des statistiques liées au compte en question, telles que :\n\nAfficher les statistiques globales/par lane/par champion du compte : le nombre de games jouées, le winrate, le kda, etc.\n\n\n\n\n\n\nCela nécessitera de se connecter à un compte admin. 1 seul sera nécessaire.\nCette classe héritera de l’ensemble des méthodes précédentes.\nCette classe aura pour but de permettre à l’admin de pouvoir gérer les comptes et les données.\n\n\n\n\n\nLes fonctionnalités avancées sont triées selon le niveau de difficulté , cependant vous êtes totalement libres sur les fonctionnalités avancées que vous souhaitez réalisées.\n\n\nJusqu’ici vous utilisez les données mises à disposition sans enrichissement. Cette fonctionnalité aura pour but de permettre à l’admin de pouvoir ajouter des nouvelles parties récentes. Les différents points attendus sont : - Gestion de la clé (permettant l’accès à l’API de Riot) : au choix entre en brute en paramètre d’entrée ou permettre d’aller la récupérer directement sur le site depuis l’API. - Récupération des données depuis l’API de Riot selon certains critères de sélection. - Ajout des données dans vos bases de données. - Ajout de la fonctionnalité au sein de votre API.\nLes critères de sélection seront libres et donc proposés par votre groupe, en fonction de ce que l’API vous permettra de faire.\n\n\n\nLe workflow Gitflow vous permet de faciliter la gestion des branches et la séparation des différentes tâches. Utilisez le framework Gitflow pour la gestion de votre projet.\n\n\n\nConteneuriser votre application aura pour but de faciliter son déploiement et son partage. En effet, cela permettra de réunir le code et ses composants (frameworks, bibliothèques, etc) dans un conteneur. Il sera alors possible d’exécuter le conteneur sans se soucier des différentes dépendances (l’installation des bibliothèques avec la bonne version par exemple).\nUtilisez l’outil Docker pour conteneuriser votre application.\n\n\n\nPour le moment, vous ne faites remonter que des statistiques descriptives. Ici il s’agit de mettre à profit l’ensemble des données disponibles pour permettre à l’utilisateur de prédire l’équipe gagnante en fonction des 5 champions de chaque équipe. L’enjeu de cette fonctionnalité n’est pas de vous faire trouver le meilleur modèle de prédiction mais d’ajouter une fonctionnalité à votre API basé sur ce modèle. Vous ne serez donc aucunement noté sur la qualité des prédictions.\nLes différents points attendus sont : - Choix d’un modèle de prédiction : vous ne serez certes pas noté sur la qualité des prédictions mais une courte réflexion sur le choix du modèle est attendue. - Entrainement dudit modèle : vous êtes libres sur le choix des librairies. - Sérialisation du modèle : vous devez sauvegarder votre modèle. - Ajout de la fonctionnalité au sein de votre API.\n\n\n\n\n\nTuteur : Sophie HERBERT, ENSAI 2021\n\n\nRecommander des produits meilleurs pour la santé selon plusieurs critères !\nVous allez explorer la célèbre API Open Food Facts qui regroupe des produits alimentaires divisés en plusieurs catégories (Viandes, Snacks, Aliments d’origine végétale etc.) et pour lesquels nous avons un grand nombre de variables renseignées par la communauté : nutriscore, nova score, ecoscore, taux de protéine, taux de sucre, énergie en kcal… L’objectif de l’application est d’utiliser un échantillon de ces données en vous concentrant sur quelques produits de quelques catégories que vous aurez choisis, de les afficher tel un catalogue et de pouvoir les trier selon le critère sélectionné : le moins de sucre possible, le meilleur eco-score, la plus faible valeur énergétique… En allant sur une fiche « Produit », vous afficherez le meilleur produit de la même catégorie selon ce critère. Un système d’identification devra être mis en place. Si l’utilisateur est identifié, pourquoi pas sauvegarder ses articles dans un panier virtuel ?\n\n\n\nLes fonctionnalités requises :\n\nF1 : affichage simple en console d’un catalogue de produits alimentaires par catégorie de produit\nF2 : ordonner les produits selon un critère nutritionnel\nF3 : sélection d’une fiche « Produit » recommandant un autre produit de la même catégorie avec un critère meilleur que le produit consulté (si meilleur il y a)\nF4 : système d’authentification et de gestion du profil (changement de mot de passe…)\n\n\n\n\n\nF5 : sauvegarde de produits dans un panier\n…\n\nDes fonctionnalités optionnelles pourront être développées à votre guise et selon votre inspiration sur le sujet ! Les données Open Food Facts étant très riches, d’autres axes d’analyses peuvent être creusés… Note : l’interface GUI, la mise en place de modèles statistiques, la gestion des valeurs manquantes ne seront pas inclues dans la notation.\n\n\n\n\n\n\n\n\n\nCe projet a pour objectif de créer une application qui facilite la recherche d’emploi dans le secteur de la technologie en utilisant l’API REST gratuite de Adzuna , qui fournit des informations sur les offres d’emploi dans divers secteurs à travers le monde. L’application permettra aux utilisateurs de rechercher des emplois, de filtrer les résultats, de suivre leur progression dans leurs candidatures et de recevoir des alertes pour les nouvelles offres correspondant à leurs compétences.\n\n\n\n\nIntégrer les données de l’API Adzuna dans une application conviviale.\nPermettre aux utilisateurs de rechercher des offres d’emploi par mots-clés, localisation et catégories.\nFournir des fonctionnalités de suivi des candidatures, y compris la gestion de CV et de lettres de motivation.\nEnvoyer des alertes aux utilisateurs pour les nouvelles offres correspondant à leurs critères.\nMettre en place un système de profil pour les chercheurs d’emploi.\n\n\n\n\nLes fonctionnalités requises :\n\nF1 : Intégrer les données de l’API Adzuna pour afficher des offres d’emploi dans divers secteurs.\nF2 : Permettre aux utilisateurs de rechercher des emplois en utilisant divers critères.\nF3 : Permettre aux utilisateurs de créer des profils de chercheurs d’emploi.\n\n\n\n\n\nF4 : Fournir des fonctionnalités de suivi des candidatures et de gestion de documents(CVs, lettres de motivation…).\nF5 : Envoyer des alertes aux utilisateurs pour les nouvelles offres correspondant à leurs compétences.\nF6:…\n\n❗ Vous avez la liberté de développer des fonctionnalités optionnelles selon votre inspiration. Aucune interface graphique n’est demandée dans ce sujet, toute interaction avec l’application devra se faire via l’invité commande ( terminal / cmd ). Si vous souhaitez tout de même le faire, cela ne saurait se substituer aux fonctionnalités demandées.\n\n\n\n\n\n\n\n\n\nCe projet vous propose d’explorer les données mises à disposition par OpenData Paris. En particulier, vous allez jouer avec les données présentant la disponibilité des Velib’ en temps réel. La solution proposera des services pour permettre aux utilisateurs de trouver plus facilement un vélo, ou pour aider la ville de Paris à mieux gérer son parc de vélos. Pour cela, vous aurez besoin de capturer et de stocker les données disponibles sur l’API d’OpenData Paris (et leur historique!) dans une base de données, puis de créer à votre tour une API pour y mettre à disposition vos services.\n\n\n\n\nF1 : obtenir le nom de la station la plus proche ayant au moins un vélo disponible à partir de coordonnées géographique. Vous pouvez utiliser l’API d’Etalab pour obtenir des coordonnées géographiques à partir de d’une adresse.\nF2 : obtenir le nom de la station la moins fréquentée sur une période de temps données.\nF3 : obtenir le numéro de l’arrondissement le plus fréquenté sur une période de temps données.\n\n\n\n\n\nF01 - Recherche de vélo en temps réel : Un utilisateur utilise la F1 pour trouver un vélo proche de lui. En arrivant sur place: mauvaise surprise, le vélo lui ai passé sous le nez. Pour éviter ce genre de désagréaments, le nom de la station la plus proche sera actualisé en temps réel. Pour cela, vous pouvez améliorer la F1 en proposant une connexion basé sur un WebSocket.\nFO2 - Déploiement : Pour faciliter le déploiement de votre solution, conteneurisez-la en utilisant Docker Compose.\nFO3 - CRUD : Permettez aux utilisateurs de communiquer directement avec votre base de données. Pour cela, complétez votre API en proposant des nouvelles routes permettant de :\n\nrécupérer toutes les informations d’une station\nsupprimer toutes les informations d’une station\nmettre à jour le nom d’une station\najouter une nouvelle station\n\n\n\n\n\nPour répondre aux fonctionnalités demandés, vous aurez certainement besoin de vous armer de:\n\nune librairie pour construire des APIs (conseillé: FastAPI)\nune solution de base de données (conseillé: SQLite)\nun outil de versioning de code en équipe (Gitlab ou Github)"
  },
  {
    "objectID": "doc/anciens-sujets.html#section",
    "href": "doc/anciens-sujets.html#section",
    "title": "Anciens sujets",
    "section": "",
    "text": "Tuteur : Cyriel Mallart\n\n\nTu veux parler musique avec des gens qui comprennent tes goûts ? Avec (NomDeVotreWebService), c’est facile ! Enregistre-toi, dis-nous ce que tu écoutes, et on t’envoie des gens qui vibrent au même rythme que toi !\nVous allez créer dans ce projet une API qui met en relation des gens, basée sur leurs goûts musicaux. Un.e utilisateur.ice s’inscrira, sélectionnera et enregistrera ses morceaux, artistes et genres préférés. L’API Deezer vous donnera accès à toutes les caractéristiques de ces morceaux. A partir de cela, vous utiliserez une touche d’IA pour trouver celui ou celle qui a le profil le plus similaire, et lui enverrez une petite notification pour mettre tout le monde en contact. Si ça ne matche pas, ou si l’utilisateur.ice veut découvrir de nouvelles personnes, on trouve le profil similaire le plus proche en excluant les gens déjà en contact ou refusés.\n\n\n\n\ngestion de plusieurs utilisateurs\nenregistrement des morceaux, artistes, genres, etc. utiles en base de données\nappels à l’API Deezer pour obtenir les informations sur les morceaux\nobtention, stockage et mise à jour des profils similaires\ngestion des notifications de mise en contact : accepté, refusé, notification à tous les utilisateur.ices impliquée.e.s\n\n\n\n\n\nauthentification par mot de passe\ngestion des “contacts” d’un utilisateur : déletion, signalement, création de groupes\nrecommendation de nouveaux morceaux basés sur ceux des contacts\nplaylists crées par fusion des morceaux des utilisateurs, export\nsélection ergonomique des morceaux (suggestions, autocomplétion, …)\nalgorithme de recommendation plus élaboré\n…\ntout autre idée qui vous semble logique, intéressante, sous réserve qu’elle soit faisable techniquement dans les temps impartis\n\n\n\n\n\nBackend : FastAPI\nFront end : Jinja2 (templates HTML dans FastAPI). D’autres choix sont possibles (React.js, Vue.js, …) si vous les maîtrisez, mais attention, votre tuteur ne pourra vous suivre que sur React.js, et la courbe d’apprentissage est raide.\nBDD : MongoDB (NoSQL) , Neo4j (NoSQL, graphe) ou Postgres (SQL, disponible à l’ENSAI)\nAPI Deezer : https://developers.deezer.com/api\n\n\n\n\n\nCréer une appli de messagerie : le but de ce projet est uniquement une mise en contact où l’on partagera une adresse mail par exemple\nSe casser la tête sur un algorithme super-classe : les performances de l’algorithme de recommendation ne sont pas le point important ici, ne passez pas tout votre projet dessus. Si vous avez envie d’essayer une idée d’algorithme, allez-y, même si elle ne fonctionne pas bien au final. Sinon, votre tuteur pourra vous aider sur un algorithme de base\nUne interface réctive super-évoluée avec des graphiques et des previews de morceaux : on attend une interface basique et simple, c’est-à-dire, des pages HTML statique écrit en noir sur fond blanc avec un ou deux boutons.\n\n\n\n\n\nTuteur : Colin Leverger Objectif\nVous êtes un groupe d’étudiants de l’ENSAI en deuxième année, et souhaitez développer une application en ligne de commande pour faciliter vos futures recherches de stage. Votre startup s’appelle ……… et votre application ………. .\nVotre application permettra à un utilisateur de rechercher des stages de son choix sur un ou plusieurs sites de recherche de stage (Hellowork, welcometothejungle, …). Les stages peuvent être publiés dans différentes spécialités (informatique, data analyse, machine learning, …). S’il est authentifié, l’utilisateur pourra sauvegarder dans l’application les stages qui l’intéressent dans sa « liste d’envies », et pourquoi pas répondre aux offres plus facilement (automatiquement, ou au minimum récupérer les contacts vers les employeurs). La navigation et les recherches de tout utilisateur seront historisées.\nDeux types d’utilisateurs authentifiés pourront cohabiter : utilisateur « élève » et utilisateur « professeur ». Un « administrateur » de l’app pourra également gérer l’application et les utilisateurs. Un utilisateur non authentifié sera par défaut dans la catégorie « élève ». On peut imaginer que les besoins des professeurs et des élèves seront différents…\nL’application permettra aux utilisateurs authentifiés de gérer leurs comptes, préférences, mots de passe, listes, et à tous les utilisateurs d’exporter/importer leurs recherches courantes (dans le format texte que vous jugerez bon).\nLes utilisateurs pourront également géo localiser les stages par rapport à leur position actuelle (temps de trajet,…).\nFonctionnalités requises (numérotées, mais non ordonnées)\n\nF1 : la recherche de résultats sur un site que vous choisirez (Hellowork, welcometothejungle, …)\nF2 : authentification et gestion du profil utilisateur/profil administrateur\nF3 : gestion de l’import/export de données au format choisi\nF4 : gestion de l’historique des recherches\nF5 : recherche par catégorie/filtre de recherches\n\nFonctionnalités optionnelles\n\nFO1 : lancer des recherches sur plusieurs sites en parallèle\nFO2 : géo localisation de l’utilisateur et des annonces/distance entre l’utilisateur et l’annonce\nFO3 : alertes automatiques si de nouvelles annonces de stage remplissant les critères sont publiées\nFO4 : … à vous de jouer !\nNOTE : ce sujet regorge de « … ». En effet, une participation active est vivement recommandée et vos idées, pour rendre votre projet unique, sont les bienvenues !\n\nFonctionnalités non notées (et déconseillées)\n\nles statistiques/modèles complexes que vous pourrez imaginer (une moyenne, OK, mais un modèle expo logarithmique quantique d’ordre 10, non)\nl’interface graphique type GUI (AUCUN point bonus sur une très jolie interface !)\n\n\n\n\nTuteur : Maxence Lagalle\n\n\nGreenStream est une API REST qui permet de réduire l’impact carbone d’un service de VOD (Netflix, Amazon Prime, Disney+…). Pour le consommateur, elle calcule l’impact carbone d’une vidéo à partir de sa durée et de sa résolution, en utilisant le modèle “1byte” de The Shift Project ou d’autres modèles d’estimation. Pour le fournisseur de VOD, elle aide à choisir des serveurs dans la meilleure zone géographique des fournisseurs Cloud en fonction de l’impact carbone de la production d’électricité. Ces données sur l’impact carbone sont fournies par l’API ElectricityMaps. GreenStream est un projet innovant et écologique, qui accompagne dans la transition vers des services de VOD plus vert et plus responsables.\nElectricityMaps est partenaire de GreenStream et offre un accès à la version payante de son API pour toute la durée du projet.\n\n\n\n\nEstimation de l’empreinte carbone d’une vidéo selon le modèle “1byte” de The Shift Project\n\nPrise en compte de la localisation géographique du fournisseur de VOD et de l’utilisateur\nPrise en compte de la durée et de la qualité de la vidéo, du type de connexion et du matériel utilisé pour regarder la vidéo\nUtilisation des données d’impact carbone en temps réel fournies par l’API ElectricityMaps\n\nRecommandation du meilleur service Cloud pour diffuser une vidéo à un utilisateur\n\nChoix du service Cloud à l’impact carbone le plus faible en fonction de la zone géographique de l’utilisateur\nDétermination des services Cloud éligibles en fonction de la localisation de l’utilisateur (ceux dans le même pays ou un pays limitrophe)\nUtilisation des données de prévision de l’impact carbone pour la durée de la vidéo fournies par l’API ElectricityMaps\n\nGestion de l’offre des fournisseurs Cloud\n\nImplémentation de la liste des zones géographiques proposées par au moins deux fournisseurs Cloud (AWS, GCP, Azure…)\nUtilisation d’une base de données SQL pour stocker les informations sur les services Cloud disponibles\n\nInformation sur l’état du service GreenStream\n\nFourniture d’un service permettant de s’assurer que GreenStream fonctionne correctement et que son lien avec ElectricityMaps est actif\n\n\n\n\n\n\nSimulation de l’impact carbone d’un changement de comportement\n\nCréation d’un service qui permet à l’utilisateur de simuler l’impact carbone qu’il aurait s’il changeait certains paramètres de sa consommation de vidéos, tels que la qualité, la durée, le type de connexion ou le matériel utilisé\nUtilisation du modèle “1byte” ou d’autres modèles d’estimation pour calculer l’empreinte carbone selon les différents scénarios\n\nUtilisation de modèles d’estimation de l’empreinte carbone plus sophistiqués\n\nPrise en compte d’une consommation électrique variable selon les fournisseurs Cloud\nUtilisation d’autres modèles d’estimation publiés, tels que le modèle “Carbon Footprint of Video Streaming” de Carbon Trust ou d’autres modèles à rechercher\n\nIntégration de critères avancés dans la recommandation du service Cloud\n\nPrise en compte du coût financier des services Cloud et d’un arbitrage entre le coût et l’empreinte carbone\nUtilisation d’un graphe de connexions entre les zones pour déterminer la liste des services Cloud éligibles pour diffuser une vidéo à un utilisateur\n\nSuivi de la consommation totale du service et de son empreinte carbone\n\nEnregistrement SQL de la consommation de vidéos : durée, zone géographique de l’utilisateur, service Cloud associé, empreinte carbone\nAccès aux données brutes ou à une synthèse statistique via l’API\n\nFonctionnement en mode dégradé\n\nUtilisation de données historiques d’intensité carbone de la production d’électricité en cas de défaillance de l’API ElectricityMaps\n\n\nL’initiative est fortement encouragée dans ce projet, et d’autres idées de fonctionnalités avancées ou d’amélioration des fonctionnalités de base peuvent être proposées par les élèves.\n\n\n\n\nTuteur : Thierry Mathé\n\n\nLe ministère des Finances met à disposition un fichier des prix des carburants dans les stations françaises. Ce fichier au format XML contient entre autre pour chaque station, ses coordonnées, son adresse, ses heures d’ouvertures, le prix des carburants disponibles (mais l’enseigne de la station n’y figure pas). Le but du projet de créer une API (application programming interface) qui exploite les données contenues dans ce fichier. Cette API devra permettre de :\n\nConsulter la liste des stations se trouvant à proximité d’un point donné il sera aussi possible de préciser le carburant.\nCréer et mettre à jour des listes de stations qu’il sera possible de consulter par exemple pour voir les prix sur les stations se trouvant sur un trajet régulier.\n\nA chaque requête, l’API doit s’assurer qu’elle utilise bien les dernières données disponibles et au besoin télécharger les nouvelles données disponibles sur le site (mises à jour toutes les 10 minutes) : https://donnees.roulez-eco.fr/opendata/instantane\n\n\n\n\n\nLes paramètres donnés à cette requête sont les coordonnées (longitude et latitude) d’un point, une distance en km et un type de carburant. L’API va alors extraire l’ensemble des stations se trouvant dans la zone ainsi définie et disponsant du carburant indiqué.\nLa réponse sera données au format JSON et contiendra:\n\nles parmètres de la requête\nla date et l’heure d’exécution\nle nombre de stations trouvées\nla liste des stations : pour chaque station on aura:\n\nl’id, les coordonnées et l’adresse de la station\nle prix du carburant\n\n\n\n\n\nLa gestion des listes de stations doit permettre de: - Créer une liste: le paramètre en entrée est un nom donné par l’utilisateur. La requête revoie un identifiant qui devra être passé comme paramètre pour toutes les autres actions, - Consulter la liste des listes crées: aucun paramètre, la requête renvoie les couple identifiant-nom des listes défines, - Ajouter une une plusieurs stations à un liste: les paramètres en entrée sont l’identifiant de la liste et le ou les identifiants des stations à ajouter, - Supprimer une liste: le paramètre à donner est l’identifiant de la liste, - Consulter la liste: le paramètre à donner est l’identifiant de la liste. La requête revoie les informations au format JSON qui contiennent: - l’identifiant et le nom de la requête - la date et l’heure d’exécution - le nombre de stations contenues dans la liste - la liste des stations. Pour chaque station on aura: - l’id, les coordonnées et l’adresse de la station - le prix du carburant\n\n\n\n\nVoici quelques idées de fonctions avancées pour les groupes qui auraient effectué l’ensemble des fonction de bases. Toutes autres idées pourra bien sûr être proposées en cours de projet. ##### Stations à proximités\n\nPossibilité de passer comme parmètre une adresse au lieu de coordonnées\nPossibilité de préciser l’heure de passage et de ne conserver que les stations ouvertes à cette heure.\n\n\n\n\nPossilité de retirer une ou plusieur stations d’une liste\nImposer une identification pour consulter les listes. Chaque utilisateurs n’aurait alors accés qu’à ses liste.\n\n\n\n\n\n\nTuteur : Aloïs DE OLIVEIRA\n\n\nLeague Of Legends (connu sous le sigle LoL) est un jeu video, plus précisément un Multiplayer Online Battle Arena (MOBA), développé par Riot. LoL comptait plus de 100M de joueurs actifs en 2022 et le chiffre n’est pas voué à diminuer dans les prochaines années. Cet engouement force Riot à se renouveler en créant de nouveaux champions, de nouveaux items, des ajustements sur l’équilibrage du jeu (appelés patch). Les joueurs apprécient donc fortement les outils leur permettant d’avoir des analyses simples mais rapides afin de les accompagner et aider dans leurs choix.\nCe sujet ne nécessite pas de connaître le jeu ou d’y avoir déjà joué. Au contraire, il vous arrivera souvent de devoir dans un premier temps comprendre un nouveau contexte métier et vos données en entrée.\n\n\n\n\n\nVous êtes mobilisés afin de mettre en place une solution capable de fournir aux joueurs les premières informations essentielles. Ces analyses seront simples mais nécessiteront d’analyser tout l’historique des parties que vous aurez à votre disposition, et donc que vous stockerez. Votre solution a pour but d’être pensée dans une logique d’amélioration continue. Ainsi un code documenté utilisant les principes de la Programmation Orientée Objet (POO) est attendu.\n\n\n\nLoL met à disposition une API afin de permettre aux personnes qui le souhaitent de pouvoir utiliser leurs données. Une explication du fonctionnement de l’API de LoL et de l’obtention des données sera effectuée.\n\n\n\n\nLors de ce projet, vous aurez des fonctionnalités obligatoires et avancées. Il est nécessaire de se focaliser sur ces premières et d’entreprendre les secondes que lorsque vous avez une base solide pour répondre à l’ensemble des fonctionnalités obligatoires.\n\n\n\nNiveau base de données\n\n\n\nCréation d’une base de données de votre choix (SQL/NoSQL) qui vous servira à stocker l’historique des parties. Le modèle de données est important, il doit être adapté afin de faciliter toutes modifications.\nCréation d’un pipeline de données. L’ensemble des étapes de la collecte au chargement, en passant par la transformation doivent être le plus réutilisable possible.\nL’ensemble des tâches doit être effectué en Python (de la création, à l’insertion et aux éventuelles modifications).\n\nNiveau API\nPour la réalisation de ce projet, vous devrez réaliser une API (à l’aide FastAPI ou Flask) qui vous permettra de renvoyer les différents résultats souhaités. Ces résultats seront à retourner sous format json. Il existera différentes classes, décrites ci-dessous, avec chacune ses méthodes. Toutes les méthodes présentes dans les descriptions des classes sont à titre indicatif. N’hésitez pas à être force de proposition.\n\n\n\n\nCela ne nécessitera aucune connexion.\nCette classe devra comporter certaines méthodes permettant de fournir des statistiques globales sur le jeu, telles que :\n\nAfficher les statistiques d’un champion : le nombre de games jouées, le winrate, le gold lead à Xmin, etc.\nTrier les champions (globalement ou par lane) selon le critère au choix parmi : nombre de games jouées, le winrate, etc.\n\n\n\n\n\n\nCela nécessitera de se connecter à un compte user.\nCette classe héritera de l’ensemble des méthodes propres à la classe invité.\nCette classe devra comporter certaines méthodes permettant de fournir des statistiques liées au compte en question, telles que :\n\nAfficher les statistiques globales/par lane/par champion du compte : le nombre de games jouées, le winrate, le kda, etc.\n\n\n\n\n\n\nCela nécessitera de se connecter à un compte admin. 1 seul sera nécessaire.\nCette classe héritera de l’ensemble des méthodes précédentes.\nCette classe aura pour but de permettre à l’admin de pouvoir gérer les comptes et les données.\n\n\n\n\n\nLes fonctionnalités avancées sont triées selon le niveau de difficulté , cependant vous êtes totalement libres sur les fonctionnalités avancées que vous souhaitez réalisées.\n\n\nJusqu’ici vous utilisez les données mises à disposition sans enrichissement. Cette fonctionnalité aura pour but de permettre à l’admin de pouvoir ajouter des nouvelles parties récentes. Les différents points attendus sont : - Gestion de la clé (permettant l’accès à l’API de Riot) : au choix entre en brute en paramètre d’entrée ou permettre d’aller la récupérer directement sur le site depuis l’API. - Récupération des données depuis l’API de Riot selon certains critères de sélection. - Ajout des données dans vos bases de données. - Ajout de la fonctionnalité au sein de votre API.\nLes critères de sélection seront libres et donc proposés par votre groupe, en fonction de ce que l’API vous permettra de faire.\n\n\n\nLe workflow Gitflow vous permet de faciliter la gestion des branches et la séparation des différentes tâches. Utilisez le framework Gitflow pour la gestion de votre projet.\n\n\n\nConteneuriser votre application aura pour but de faciliter son déploiement et son partage. En effet, cela permettra de réunir le code et ses composants (frameworks, bibliothèques, etc) dans un conteneur. Il sera alors possible d’exécuter le conteneur sans se soucier des différentes dépendances (l’installation des bibliothèques avec la bonne version par exemple).\nUtilisez l’outil Docker pour conteneuriser votre application.\n\n\n\nPour le moment, vous ne faites remonter que des statistiques descriptives. Ici il s’agit de mettre à profit l’ensemble des données disponibles pour permettre à l’utilisateur de prédire l’équipe gagnante en fonction des 5 champions de chaque équipe. L’enjeu de cette fonctionnalité n’est pas de vous faire trouver le meilleur modèle de prédiction mais d’ajouter une fonctionnalité à votre API basé sur ce modèle. Vous ne serez donc aucunement noté sur la qualité des prédictions.\nLes différents points attendus sont : - Choix d’un modèle de prédiction : vous ne serez certes pas noté sur la qualité des prédictions mais une courte réflexion sur le choix du modèle est attendue. - Entrainement dudit modèle : vous êtes libres sur le choix des librairies. - Sérialisation du modèle : vous devez sauvegarder votre modèle. - Ajout de la fonctionnalité au sein de votre API.\n\n\n\n\n\nTuteur : Sophie HERBERT, ENSAI 2021\n\n\nRecommander des produits meilleurs pour la santé selon plusieurs critères !\nVous allez explorer la célèbre API Open Food Facts qui regroupe des produits alimentaires divisés en plusieurs catégories (Viandes, Snacks, Aliments d’origine végétale etc.) et pour lesquels nous avons un grand nombre de variables renseignées par la communauté : nutriscore, nova score, ecoscore, taux de protéine, taux de sucre, énergie en kcal… L’objectif de l’application est d’utiliser un échantillon de ces données en vous concentrant sur quelques produits de quelques catégories que vous aurez choisis, de les afficher tel un catalogue et de pouvoir les trier selon le critère sélectionné : le moins de sucre possible, le meilleur eco-score, la plus faible valeur énergétique… En allant sur une fiche « Produit », vous afficherez le meilleur produit de la même catégorie selon ce critère. Un système d’identification devra être mis en place. Si l’utilisateur est identifié, pourquoi pas sauvegarder ses articles dans un panier virtuel ?\n\n\n\nLes fonctionnalités requises :\n\nF1 : affichage simple en console d’un catalogue de produits alimentaires par catégorie de produit\nF2 : ordonner les produits selon un critère nutritionnel\nF3 : sélection d’une fiche « Produit » recommandant un autre produit de la même catégorie avec un critère meilleur que le produit consulté (si meilleur il y a)\nF4 : système d’authentification et de gestion du profil (changement de mot de passe…)\n\n\n\n\n\nF5 : sauvegarde de produits dans un panier\n…\n\nDes fonctionnalités optionnelles pourront être développées à votre guise et selon votre inspiration sur le sujet ! Les données Open Food Facts étant très riches, d’autres axes d’analyses peuvent être creusés… Note : l’interface GUI, la mise en place de modèles statistiques, la gestion des valeurs manquantes ne seront pas inclues dans la notation.\n\n\n\n\n\n\n\n\n\nCe projet a pour objectif de créer une application qui facilite la recherche d’emploi dans le secteur de la technologie en utilisant l’API REST gratuite de Adzuna , qui fournit des informations sur les offres d’emploi dans divers secteurs à travers le monde. L’application permettra aux utilisateurs de rechercher des emplois, de filtrer les résultats, de suivre leur progression dans leurs candidatures et de recevoir des alertes pour les nouvelles offres correspondant à leurs compétences.\n\n\n\n\nIntégrer les données de l’API Adzuna dans une application conviviale.\nPermettre aux utilisateurs de rechercher des offres d’emploi par mots-clés, localisation et catégories.\nFournir des fonctionnalités de suivi des candidatures, y compris la gestion de CV et de lettres de motivation.\nEnvoyer des alertes aux utilisateurs pour les nouvelles offres correspondant à leurs critères.\nMettre en place un système de profil pour les chercheurs d’emploi.\n\n\n\n\nLes fonctionnalités requises :\n\nF1 : Intégrer les données de l’API Adzuna pour afficher des offres d’emploi dans divers secteurs.\nF2 : Permettre aux utilisateurs de rechercher des emplois en utilisant divers critères.\nF3 : Permettre aux utilisateurs de créer des profils de chercheurs d’emploi.\n\n\n\n\n\nF4 : Fournir des fonctionnalités de suivi des candidatures et de gestion de documents(CVs, lettres de motivation…).\nF5 : Envoyer des alertes aux utilisateurs pour les nouvelles offres correspondant à leurs compétences.\nF6:…\n\n❗ Vous avez la liberté de développer des fonctionnalités optionnelles selon votre inspiration. Aucune interface graphique n’est demandée dans ce sujet, toute interaction avec l’application devra se faire via l’invité commande ( terminal / cmd ). Si vous souhaitez tout de même le faire, cela ne saurait se substituer aux fonctionnalités demandées.\n\n\n\n\n\n\n\n\n\nCe projet vous propose d’explorer les données mises à disposition par OpenData Paris. En particulier, vous allez jouer avec les données présentant la disponibilité des Velib’ en temps réel. La solution proposera des services pour permettre aux utilisateurs de trouver plus facilement un vélo, ou pour aider la ville de Paris à mieux gérer son parc de vélos. Pour cela, vous aurez besoin de capturer et de stocker les données disponibles sur l’API d’OpenData Paris (et leur historique!) dans une base de données, puis de créer à votre tour une API pour y mettre à disposition vos services.\n\n\n\n\nF1 : obtenir le nom de la station la plus proche ayant au moins un vélo disponible à partir de coordonnées géographique. Vous pouvez utiliser l’API d’Etalab pour obtenir des coordonnées géographiques à partir de d’une adresse.\nF2 : obtenir le nom de la station la moins fréquentée sur une période de temps données.\nF3 : obtenir le numéro de l’arrondissement le plus fréquenté sur une période de temps données.\n\n\n\n\n\nF01 - Recherche de vélo en temps réel : Un utilisateur utilise la F1 pour trouver un vélo proche de lui. En arrivant sur place: mauvaise surprise, le vélo lui ai passé sous le nez. Pour éviter ce genre de désagréaments, le nom de la station la plus proche sera actualisé en temps réel. Pour cela, vous pouvez améliorer la F1 en proposant une connexion basé sur un WebSocket.\nFO2 - Déploiement : Pour faciliter le déploiement de votre solution, conteneurisez-la en utilisant Docker Compose.\nFO3 - CRUD : Permettez aux utilisateurs de communiquer directement avec votre base de données. Pour cela, complétez votre API en proposant des nouvelles routes permettant de :\n\nrécupérer toutes les informations d’une station\nsupprimer toutes les informations d’une station\nmettre à jour le nom d’une station\najouter une nouvelle station\n\n\n\n\n\nPour répondre aux fonctionnalités demandés, vous aurez certainement besoin de vous armer de:\n\nune librairie pour construire des APIs (conseillé: FastAPI)\nune solution de base de données (conseillé: SQLite)\nun outil de versioning de code en équipe (Gitlab ou Github)"
  },
  {
    "objectID": "doc/anciens-sujets.html#section-1",
    "href": "doc/anciens-sujets.html#section-1",
    "title": "Anciens sujets",
    "section": "2022-2023",
    "text": "2022-2023\n\nGestion de petites annonces 📰💰🏷\nTutuer : Colin Leverger\n\nObjectif\nVous êtes un groupe d’amateurs de shopping sur le web, et souhaitez développer une application en ligne de commande pour faciliter les achats sur internet. Votre startup s’appelle __________ et votre application ________.\nVotre application permettra à un utilisateur de rechercher des articles de son choix sur un ou plusieurs sites de vente (Leboncoin, Vivastreet, …). Les articles peuvent être présents dans différentes catégories (voitures, consoles,…). S’il est authentifié, l’utilisateur pourra sauvegarder dans l’application les articles/informations/pages web/… qui l’intéressent dans sa « liste d’envies ». La navigation et les recherches de tout utilisateur seront historisées.\nDeux types d’utilisateurs authentifiés pourront cohabiter : utilisateur « particulier » et utilisateur « pro ». Un « administrateur » de l’app pourra également gérer l’application et les utilisateurs. Un utilisateur non authentifié sera par défaut dans la catégorie « particulier ». On peut imaginer que les besoins des professionnels et des particuliers seront différents…\nL’application permettra aux utilisateurs authentifiés de gérer leurs comptes, préférences, mots de passe, listes, et à tous les utilisateurs d’exporter/importer leurs recherches courantes (dans le format texte que vous jugerez bon).\nLes utilisateurs pourront également géo localiser les annonces par rapport à leur position actuelle (temps de trajet,…).\nFonctionnalités requises (numérotées, mais non ordonnées)\n\nF1 : la recherche de résultats sur un site que vous choisirez (Leboncoin, Vivastreet, …)\nF2 : authentification et gestion du profil utilisateur/profil administrateur\nF3 : gestion de l’import/export de données au format choisi\nF4 : gestion de l’historique des recherches\nF5 : recherche par catégorie/filtre de recherches\n\nFonctionnalités optionnelles\n\nFO1 : lancer des recherches sur plusieurs sites en parallèle\nFO2 : géo localisation de l’utilisateur et des annonces/distance entre l’utilisateur et l’annonce\nFO3 : … à vous de jouer !\n\n\nNOTE : ce sujet regorge de « … ». En effet, une participation active est vivement recommandée et vos idées, pour rendre votre projet unique, sont les bienvenues !\n\nFonctionnalités non notées (et déconseillées)\n\nles statistiques/modèles complexes que vous pourrez imaginer (une moyenne, OK, mais un modèle expo logarithmique quantique d’ordre 10, non)\nl’interface graphique type GUI (AUCUN point bonus sur une très jolie interface !)\n\n\n\n\nWebservice de génération de jeux de données 📡 🌐 💽\nTuteur : Antoine Brunetti\n\nContexte\nDans le cadre de la réalisation de tests de programmes, on est souvent amenés a utiliser des jeux de données fictives.\nPour répondre à ce besoin, vous envisagez de constituer un produit qui permet de générer des données de tests pour des statisticiens et développeurs en herbe.\nLes utilisateurs de cette API pourront renseigner des types de données pour la génération à partir d’un language dédié : Par exemple : - définir un type SEXE qui ne prendrait que les valeurs M,F ou A\n\"SEXE\":\"'M'|'F'|'A'\"\n\nou définir un type composé VOITURE qui prendrait les valeurs composées :\n\n{\n    \"VOITURE\": {\n    \"nb_roues\": \"INT\",\n    \"COULEUR\": \"'rouge'|'vert'|'bleu'\"\n    }\n}\nLes utilisateurs de l’application définiront ensuite des schémas de données permettant de gérer les métadonnées nécessaires à la génération de données. Ces informations seront stockées en base de données.\nPar exemple :\n{\n    \"sexe\": {\n        \"type\": \"SEXE\",\n        \"remplissage\": 100\n    },\n    \"age\": {\n        \"type\": \"18|19|20\",\n        \"remplissage\": 100\n    },\n    \"prenom\": {\n        \"type\": \"NAME\",\n        \"remplissage\": 88.4\n    },\n    \"nom\": {\n        \"type\": \"NAME|'dupont'\"\n        \"remplissage\": 85\n    }\n}\nIl faudra également qu’a partir d’un jeu de configuration fourni au format JSON au démarrage de l’application, vous définissiez le point d’entrée d’accès aux données générées. Cela permettra une meilleure utilisation de votre API pour permettre aux utilisateurs de tester un endpoint sans modifier leur configuration.\nLa génération de ces données devra se faire selon différents formats , avec la possibilité de définir des seuils de remplissage en amont de la génération des données.\nLes différents jeux de données générés seront eux aussi sauvegardés pour permettre d’accéder aux données de manière stable (par une graine 🌱), cette graine pourra être fournie par un HEADER HTTP propre a votre application.\nLe point d’entrée de définition du schéma de données sera accessible en GET a un point d’entrée fixe de votre serveur.\n\n\nFonctionnalités de bases\n\nDéfinition des valeurs possibles pour un champ\nDéfinition d’un schéma correspondant a une ligne de données à générer.\nDéfinition d’un taux de remplissage pour un champ.\nDémarrage de l’applicatif à partir d’un fichier de règles de bases\nLa réalisation d’un scénario d’usage de l’API.\n\n\n\nFonctionnalités avancées\n\nGénération d’un jeu de règles à partir d’un jeu de données\nGestion de l’authentification à l’API\nPermettre l’export et l’import de schémas sous format JSON\nProposer une solution répondant à des enjeux de volumétrie (taille des jeux de données)\nRéalisation de rapports de statistiques sur les jeux générés.\n\n\n\n\n\nJeux de mot 📖 🏆\nTuteur : Armelle Koehl\n\nPrésentation\nWordle, zutom, le mot et tous ces dérivés d’u célèbre jeu télévisé. C’est dans la ligné de ces jeux que nous souhaitons nous inscrire en faisant notre propre version. Et pourquoi pas, le proposer comme occupation entre 2 amphis aux ensaiens 🎮 Le but du jeu est de deviner un mot spécifique en un minimum de tentatives. Le joueur inscrit sur la première ligne un mot de son choix de même longueur que le mot à deviner et entre sa proposition. Le jeu lui indique alors quelles lettres ne se trouvent pas dans le mots, celles qui y sont mais mal placées et celles qui s’y trouvent et qui sont bien placées. En fonction du nombre de tentatives, on peut proposer un score au joueur. 🏆\n\n\nFonctionnalités de base\n\nUn historique afin de reprendre sa partie en cours de route\nUn tableau des scores général s’actualisant en temps réel\nDes tests unitaires\nUne interface console simple à destination des clients qui utilisera votre API (cf architecture client serveur)\n\n\n\nFonctionnalités avancées\n\nProposer le jeu en multilingues\nCréation de listes de mots personnalisées\nUn client permettant de jouer en multijoueur local et distant\nUne gestion de l’authentification\n\n\n\nLes outils\n\nUtilisation d’une API fournissant des mots au hasard\nFramework fastApi\nBase Postgres\nGit et son univers\nVscode\n\n\n\nCe qu’on essaiera de voir en plus\n\n\n\n\nConférence de jeu de rôle 🏰🐉\nTuteur : Cyriel Mallart\n\nPrésentation\nUne nouvelle convention de jeu de rôle arrive à Rennes ! L’activité phare de la convention sera un weekend dédié à la pratique des jeux de rôles. Plusieurs jeux se dérouleront en parallèle, chacun à une table contenant un maître/une maîtresse du jeu (MJ), ainsi que des joueurs et joueuses. Le but de ce weekend est de réunir des gens de tous horizons, de donner une première impression du jeu de rôle aux personnes n’ayant jamais essayé, mais aussi de satisfaire les joueurs plus expérimentés. Le système de jeu utilisé est Dongeons et Dragons 5E.\nLes organisateurs vous sollicitent pour créer une application qui permette de gérer les tables de jeu de la conférence. Il faudra créer deux interfaces différentes : une pour les organisateurs et une pour un joueur ou MJ.\nUn joueur ou une joueuse s’inscrit à la conférence en renseignant un nouveau profil. Sur ce profil, il ou elle peut déclarer des personnages différents. En utilisant l’API disponible à l’adresse https://www.dnd5eapi.co/, plus d’informations seront colléctées sur chaque personnage, et completeront sa fiche, comme les langues que le personnage parle, ses capacités physiques, etc. Une joueuse doit aussi pouvoir s’inscrire à une table, et consulter les tables auxquelles elle joue. Les MJs ont accès à un profil similaire, où ils peuvent se porter volontaires pour plusieurs scénarios (et donc plusieurs tables). Le MJ doit aussi avoir accès à une liste des joueurs et des personnages qui seront à sa table, afin de pouvoir se préparer au mieux.\nLes organisateurs se réservent le droit de supprimer des joueurs et des MJ, et de réorganiser les tables. Dans ce cas, un tel évènement sera notifié aux joueurs concernés lorsqu’ils iront consulter les tables auxquelles ils jouent.\n\n\nFonctionnalités attendues\n\nAuthentification sommaire des profils organisateur/joueur/MJ\nInscription pour un nouveau joueur ou MJ\nComplétion des fiches personnages via l’API\nInscription/désistement à une table (avec gestion des contraintes)\nVue du programme individuel pour chaque joueur\nAjout/suppression des joueurs à une table\nCréation/suppession de tables\nVue générale du programme (tables, joueurs, MJs et horaires)\n\n\n\nFonctionnalités avancées\n\nRecherche du programme d’un joueur particulier par un organisateur\nValidation des personnages par le MJ avant inscription définitive à une table\nGestion d’un second système de jeu (Pathfinder, Call of Chtulu ou Monster of the Week, par exemple)\n\n❗ Aucune interface graphique n’est demandée dans ce sujet. Si vous souhaitez tout de même le faire, cela ne saurait se substituer aux fonctionnalités demandées.\n\n\nTechnologies utilisées\n\nFastApi\nBase de donnée au choix (SQL comme PostGres ou MySQL, ou NoSQL comme MongoDB)\nAPI D&D5e\n\n\n\n\nProfite au MAX de ton TGVMAX 🚆 : TGVMAXimizer\nTuteur : Mansor Gueye\n\nPrésentation\nVous avez un abonnement TGVMAX (Jeune 🧑 👩 ou Senior 🧓👵)et vous avez du mal à trouver des trajets éligibles, TGVMAXimizer est LA solution. TGVMAXimizer est l’application qui facilite la recherche de places disponibles pour les trajets éligibles au TGVMax. L’utilisateur crée un compte avec un profil jeune ou senior. Une fois authentifié, l’utilsateur pourra lancer une recherche en specififant la gare de depart, la gare de déstination et éventuellement la date de départ. Le resultat sera la liste des trajets éligibles au TGVMAX junior ou senior selon le profil de l’utilisateur. Les données sur la disponibilité à 30 jours de places MAX JEUNE et MAX SENIOR sont accessibles via l’api tgvmax disponible sur le site https://data.sncf.com/explore/dataset/tgvmax/api/\n\n\nFonctionnalités attendues\n\nCréation de compte\nUne gestion de l’authentification\nPossibilité de déconnexion\nRecherche de trajets éligibles au MAX JEUNE / MAX SENIOR\nFiltre pour ne voir que les places à 0 euro\n\n\n\nFonctionnalités avancées\n\nRecherche de toutes les destinations atteignables avec des places éligibles au MAX JEUNE / MAX SENIOR (y compris le trajet de retour) durant un weekend\nRecherche de toutes les destinations atteignables avec des places à 0 euros (y compris le trajet de retour) durant un weekend\nUtilisation d’une architecture serveless avec AWS lambda pour executer du code python en réponse à un événement (event trigger)\nCréer un systeme d’alerte pour envoyer une notification par email quand une place remplissant les critère de recherche se libère.\n\n❗ Aucune interface graphique n’est demandée dans ce sujet, toute interaction avec l’application devra se faire via l’invité commande ( terminal / cmd ). Si vous souhaitez tout de même le faire, cela ne saurait se substituer aux fonctionnalités demandées.\n\n\nLes outils\n\nFastApi\nBase de donnée au choix (SQL comme PostGres ou MySQL, ou NoSQL comme MongoDB)\nVersioning avec Git\nIDE de votre choix\n\n\n\n\nRap Analytics 🎶🎤📈\nTuteur : Samuel Goutin\n\nContexte\nRapminerz.io est un Data-Média pour le Rap FR. Notre ambition est d’utiliser les plus récentes innovations technologiques pour offrir à une communauté de passionnés une vision approfondie et inédite du Rap Francophone. Le projet est né de l’idée de parler de rap autrement, en mettant à jour des phénomènes impossibles à percevoir lors d’une simple écoute. Nous exploitons la force de la data science pour traiter du rap dans sa globalité. Pour cela, nous avons agrégé une des plus grandes bases de données du Rap Français avec plus de 120k morceaux. Nous vous proposons de participer à l’analyse de cette montagne de données. Prêts ? Codez !\n\n\nSujet\n\nObjectif\nVous êtes chargé de développer une solution capable de fournir à la communauté de Rapminerz des analyses pertinentes sur les featuring des rappeurs Français. Les analyses sont des chiffres clés, des indicateurs ou des prédictions qui nécessite d’analyser tout l’historique de données à votre disposition. Votre solution doit donc stocker l’historique des données. On souhaite que les analyses soient consultables depuis un navigateur web (via des requêtes HTTP). La communauté de Rapminerz compte aujourd’hui plus de 50k personnes. Cela fait autant d’utilisateur potentiels de vos analyses. Aussi, la source de données peut être amenée à grossir. Votre solution doit donc supporter une augmentation du nombre d’utilisateurs et de la quantité de données. Enfin, votre solution continuera à évoluer. Elle doit être pensée pour faciliter l’ajout de nouvelles fonctionnalités.\nUtilisez les principe de la Programmation Orientée Objet et privilégiez un code documenté et testé comme vu en TP.\n\n\nLes données\nVous avez à disposition un flux de données à l’adresse suivante https://apps-dev.rapminerz.io/data-ensai/. Il contient une liste de featuring décrit par les champs :\n\ndate : sous la forme d’un timestamp.\nprimary_artist_name : le nom de l’artiste en tête d’affiche de la chanson.\nfeatured_artists_names : la liste des noms des artistes en featuring sur la chanson.\n\nLes données sont brutes, et nécessitent donc d’être nettoyées et transformées. Chaque semaine, des nouvelles données sont intégrées aux flux, et les plus anciennes sont retirées.\n\n\n\nFonctionnalités\nLes fonctionnalités décrites dans la suite permettent de répondre au sujet, en tenant compte des contraintes sous jacentes.\nVous devez implémenter toutes les fonctionnalités attendues ainsi qu’au moins une fonctionnalité avancée de votre choix.\n\n\nFonctionnalités attendues\n\nFO1 : Mise en place d’une base de données\n\nChoisissez une base de données de votre choix (SQL/NoSQL) pour y stocker l’historique de vos données, en vous assurant de ne pas introduire de doublons. Vous pouvez par exemple utiliser la librairie sqlite3.\nToutes les opérations liées à votre base de données telle que la création de tables, les insertions et les lectures devront être pilotées en Python.\nChoissisez un modèle de données qui facilitera les modifications. Par exemple, le changement de nom d’un artiste ne doit nécessiter qu’une seule instruction (type UPDATE TABLE). Inspirez-vous de la modélisation en étoile.\n\n\n\nFO2 : Construction d’un pipeline de données\n\nDef: Pipeline de données : Un pipeline de données est un concept informatique faisant référence aux étapes de transport des données d’une source vers une cible. Parmi ces étapes, on peut y retrouver la collecte, l’organisation ou encore la transformation des données.\n\n\nDef: Pipeline ETL: Un pipeline ETL est un pipeline de données spécial comprenant uniquement des étapes de collecte (E), de transformation (T) et de chargement (L) des données vers une cible.\n\n\nDef: Orchestrateur: Un orchestrateur de pipeline est un outil permettant de chainer les étapes d’une pipeline et de gérer les dépendances entre étapes.\n\n\nVotre pipeline sera composée des étapes suivantes :\n\nCollecte de la source de données,\nQuelques étapes de transformation (nettoyage, typage, encodage, etc..),\nChargement dans la base de données.\n\nChacune des étapes de votre pipeline devra être générique et réutilisable. Dans l’idéal, chaque étape doit correspondre à une fonction.\nLe plan d’exécution de la pipeline sera défini dans un fichier de configuration (en json ou yaml). Ce fichier contiendra la liste des étapes à exécuter ainsi que leurs paramètres. Il devra lu et interprété par Python lors d’une exécution de la pipeline. Vous pouvez utiliser les librairies json ou PyYAML pour cela.\nVous pourrez ainsi créer plusieurs configurations différentes pour votre pipeline.\nL’exécution de d’une pipeline se fera via l’interface en ligne de commande. Le chemin vers votre fichier de configuration pourra être placée en argument de la commande en utilisant la libraire argparse.\nL’orchestration des étapes de votre pipeline pourra se faire avec des outils dédiés tel que Pandas pipe ou genpipes.\n\n\n\nAttention à ne pas introduire de doublons dans la base de données! Vous pouvez utilisez le champ date comme point de repère.\n\n\n\nFO3 : Mise en place d’une API et exposition de résultats simples\n\nMettez en place une API REST en utilisant FastAPI ou Flask.\nAjoutez une route nommée /count-feat qui retourne le résultat de la requête suivante :\n\nLe nombre de featuring par artiste et par mois. Un featuring est comptabilisé lorsque l’artiste est primary_artist ou featured_artist.\n\nAjoutez une route nommée /mean-feat qui retourne le résultat de la requête suivante :\n\nLa moyenne mobile du nombre total de featuring par jour avec une fenêtre de 5.\n\nRetournez les résultats au format json.\n\n\n\nFO4 : Accélération des appels à l’API\nPour permettre à votre API de supporter un grand nombre de requête simultanées, vous devez implémenter au moins l’une des deux solutions suivantes.\nPré-calcul\nVous pouvez accélérer le calcul d’une requête en pré-calculant tout ou partie des résultats.\n\nCalculez tout ou partie de la requête et stockez là dans un fichier csv ou json que l’on appelle une vue.\nModifiez votre API afin qu’elle tire profit de ce fichier.\nVeillez à tenir à jour votre vue en effectuant des synchronisations régulières avec la base de données.\n\n\nCache\nVous pouvez accélérer le calcul d’une requête en cachant ses résultats en mémoire.\n\nDef: Cache: Une mémoire cache une mémoire qui enregistre temporairement des copies de données provenant d’une source, afin de diminuer le temps d’un accès ultérieur (en lecture) à ces données.\n\n\nLors du premier appel la requête n’existe pas dans le cache. Elle est donc calculée à partir des données de la base de données. Le résultat est renvoyé à l’utilisateur et stocké dans le cache pour anticiper les futurs appels.\nLors du second appel (et des suivants), le résultat de la requête est déjà présents dans le cache. Le résultat est renvoyé de manière quasi instantanée à l’utilisateur.\nVous pouvez utilisez la librairie cachetools pour implémenter un cache.\n\n\n\n\n\nFonctionnalités avancées\nLes fonctionnalités difficiles seront davantage valorisées que les fonctionnalités faciles.\n\nFA1 [difficulté : facile] : Implémentation d’un système d’authentification à l’API\nPour sécuriser votre API, implementez un système d’authentification. L’utilisateur devra être muni d’un token pour pouvoir utiliser votre service.\n\n\nFA2 [difficulté : facile] : Utilisation du workflow Gitflow\nLorsque vous travaillez en équipe sur un projet de développement, adoptez le framework Gitflow pour une meilleure gestion des branches.\n\n\nFA3 [difficulté : moyen] : Exposez un modèle de Machine Learning\nOffrez la possibilité à vos utilisateurs d’obtenir la prédiction du nombre de featuring total pour les prochains mois.\n❗ Vous ne serez pas évalué sur la qualité de votre modèle.\n\nEntrainez un modèle de prévision de série temporelle basique à prévoir le nombre de featuring total.\nVous pouvez utiliser la méthode du lissage exponentiel pour générer des prévisions en utilisant la librairie statsmodels.\nAprès l’avoir entrainé, sérialisez le modèle en utilisant la librairie pickle afin de le sauvegarder dans un fichier.\nAjoutez une route nommée /predict-feat à votre API qui retourne une prédiction du modèle.\nAjoutez la possibilité de déclancher un ré-entrainement du modèle avec l’interface en ligne de commande.\n\n\n\nFA4 [difficulté : moyen] : Mise en place d’une chaine d’intégration continue\n\nDef: Intégration Continue: Consiste à intégrer les changements apportés au code informatique d’un projet logiciel de façon continuelle, afin de détecter et de corriger immédiatement les éventuelles erreurs.\n\nMettez en place une chaine d’intégration continue basique avec Gitlab-CI ou Github Actions.\nVotre chaine d’intégration continue pourra comporter deux étapes : - une étape d’exécution des tests avec la librairie unittest ou pytest - une étape de qualité du code avec la librairie flake8\n\n\nFA5 [difficulté : élevée] : Conteneurisez votre application\n\nDef: Conteneurisation: Consiste à rassembler le code du logiciel et tous ses composants (bibliothèques, frameworks et autres dépendances) de manière à les isoler dans leur propre « conteneur ».\n\nConteuneurisez l’ensemble de votre solution en utilisant Docker.\n\n\n\n\nAPI cadastrale 🗺🏘🏗\nTuteur : Thierry Mathé\n\nLe contexte\nLe service statistique du ministère de la Transition écologique gère « Sitadel », le répertoire des autorisations d’urbanismes. À partir de ce répertoire le service publie des chiffres sur le nombre de permis de construire (PC) autorisés et le nombre de logements dont la construction est autorisée sur chaque commune. Une demande de PC doit se faire sur un terrain s’étendant sur une ou plusieurs parcelles cadastrales contiguës. Il est possible que ces parcelles se trouvent sur des communes différentes voire sur des départements différents. Lorsque c’est le cas, une demande de PC doit être faite sur chaque commune concernée. Cette situation peut donc engendrer des doublons au niveau du décompte des PC et des logements autorisés. Ce phénomène existe mais à l’heure actuelle on ignore s’il est fréquent et si les erreurs engendrées ont un poids notable sur les chiffres publiés au niveau communal. Le but de ce projet est d’apporter des outils qui aideront à l’étude de ce phénomène. Pour détecter les PC à cheval sur plusieurs communes, il convient de connaître les parcelles cadastrales qui sont en bordure de commune, puis de trouver les PC se trouvant sur ces parcelles et enfin déterminer lesquels de ces PC se trouvent sur des parcelles contiguës afin de voir s’il s’agit de la même construction ou non.\n\n\nLes développements obligatoires\nLe projet a pour but premier de créer une API capable de répondre aux requêtes suivantes :\n\nquelles sont les communes ayant des parcelles contiguës à une commune donnée ?\nquelles sont les parcelles en limite d’une commune donnée ?\nquelles sont les parcelles contiguës à une parcelle donnée ?\n\nPour cela il faudra exploiter les fichiers geoJSON du site : https://cadastre.data.gouv.fr/datasets/cadastre-etalab.\nCe site contient des fichiers communaux des limites des parcelles adastrales. Chaque parcelle est délimitée par un polygone. Deux parcelles sont contiguës si elles partagent un même segment.\nLe premier travail sera donc de créer à partir de ces fichiers une base de données qui stockera les communes et les parcelles contiguës. Pour des raisons de volumétrie des données, ce travail ne sera effectué que sur un département, mais le programme de construction de la base et la base elle-même devront être capables de traiter plusieurs départements. De plus, le programme de construction de la base devra être facilement paramétrable pour changer la zone géographique couverte et l’année de géographie. Le second travail sera la construction de l’API qui répondra aux requêtes pré-citées en exploitant la base de données.\n\n\nDéveloppement optionnel\nDans un second temps, les groupes qui en auront la possibilité pourront faire des recherches sur les PC à partir des données Sitadel disponibles au format CSV sur le site du ministère : https://www.statistiques.developpement-durable.gouv.fr/liste-des-permis-de-construire-et-autres-autorisations-durbanisme Étant donné une commune de référence, il faudra rechercher les communes qui lui sont contiguës et extraire les PC de toutes ces communes. En suite il faudra dresser la liste des parcelles en limite de la commune de référence et de toutes les parcelles qui leur sont contiguës dans les autres communes et lister les PC présents sur ces parcelles. Enfin il faudra rapprocher les PC contiguës\nCe programme de recherche devra donc fournir en sortie cette liste de PC contiguës qui sera ensuite analysée pour voir s’il s’agit d’un même projet de construction ou pas.\n\n\n\nLa pyramide et le philosophe 📖 🔗\nTuteur : Suliac Le Guillou\n\nPrésentation\nAprès le succès des Worlde et Sutom cette année, je vous propose de revisiter un autre jeu télévisé: Pyramide. Dans ce jeu, le maitre des mots doit faire deviner un mot à son équipier en lui donnant pour indice des synonymes.\nPour renouveler ce concept, je vous propose de coupler ce concept avec un rare jeux de l’internet: le philosophe. Ici vous devez choisir un article au hasard sur Wikipedia et naviguer les liens hypertext jusqu’a tomber sur la page de philosophie\nVous aurez ainsi à construire une version pour un joueur de Pyramide en vous aidant de Wikipedia: votre programme devra aller chercher un article au hasard sur la fameuse encyclopédie et distribuer des indices au joueur pour lui faire deviner\n\n\nFonctionnalités de base\n\nConstruire votre énigme\nFiltrer les indices\nDes tests unitaires\nUne interface console simple à destination\n\n\n\nFonctionnalités avancées\n\nFiltrer les articles injouable\nReconnaitre des catégories pour donner plus d’indices (biologie, mathématique, jeux vidéo)\nUn tableau des scores\nDes variantes de jeux\nUne version deux joueurs\nSelection de language\n\n\n\nLes outils\n\nWikipedia\nBase Postgres\nGit\nVscode"
  },
  {
    "objectID": "doc/notice-eleves.html",
    "href": "doc/notice-eleves.html",
    "title": "Notice élèves projet informatique 2A 2023-2024",
    "section": "",
    "text": "🚧 draft\n\nIntroduction\nTous les élèves de deuxième année (exceptés ceux suivant le parcours Recherche ATPA), participent à la réalisation du projet informatique. Ils sont répartis en groupes de 4 à 5 élèves. Ce projet permet d’effectuer un approfondissement et une mise en pratique des connaissances acquises lors des enseignements informatiques de 1ère année. La composition des groupes est définie par le département d’enseignement informatique.\n\nLe travail demandé consiste à construire une application permettant de répondre à la problématique du sujet proposé. Ce travail se décompose en 3 grandes phases :\n\nUne phase d’étude préalable pour décrire la solution envisagée et planifier les grandes phases de la réalisation (diagramme de cas d’utilisation et diagramme de Gantt) ;\nUne phase de conception générale de l’application pour décrire les exigences fonctionnelles générales par la modélisation (diagramme d’activité ou d’états, diagramme de classes, modèle de données …) et planifier la mise en place des fonctionnalités (dépendances, priorités, …) ;\nUne phase de réalisation :\n\nMise en place de la base de données ;\nDéveloppement continu du système en python3 accompagné d’une description graphique du ou des modèles choisis (le modèle d’implémentation) ;\n\n\nÀ mi projet, vous livrerez le dossier d’analyse correspondant au travail réalisé lors des 2 premières phases. En fin de projet, vous devrez rendre un dossier complet. Vous présenterez vos travaux lors d’une soutenance orale. 1. ## Organisation 1 ### Les groupes de projet Les groupes ont été composés par le responsable de la matière en tenant compte des niveaux constatés en informatique lors de la première année et en veillant à la répartition des élèves admis sur titre. La composition des groupes n’est pas modifiable. Il est essentiel de veiller à la bonne intégration des élèves admis sur titre au sein des groupes. 1 ### Choix du sujet Chaque intervenant de projet a proposé un sujet qui devra permettre l’application de l’ensemble des enseignements informatiques dispensés en 1ère année (conception d’applications avec UML, algorithmique, programmation objet avec Python et bases de données relationnelles). Cet intervenant prendra en charge les groupes d’élèves qui traiteront le sujet qu’il a proposé.\nVous devrez choisir votre sujet dans la liste accessible sur la plateforme d’enseignement Moodle, suivant la procédure détaillée ci-dessous :\n\nPrenez connaissance des sujets présentés sur la plateforme d’enseignement ;\nConcertez-vous entre membres d’un même groupe ;\nOrdonnez les sujets par ordre de préférence sur l’application en ligne accessible via un lien sur le cours Moodle du projet.\n\nRemarque : L’attribution des sujets se fait par une procédure automatique en essayant de respecter au maximum la préférence des groupes. Une fois attribué, les sujets ne peuvent pas être modifiés. 1 ### Encadrement et suivi d’avancement L’encadrement de l’avancement du projet se déroulera généralement sur 3 heures par semaine. Chaque groupe fera le bilan avec son intervenant du travail qui a été réalisé au cours de la semaine, des difficultés rencontrées et de ce qui doit encore être fait. Afin de formaliser ces échanges, vous pourrez vous appuyez sur une fiche de suivi de séance (voir fiche sur Moodle) ou montrer un kanban correctement rempli.\nAvant cet échange, les élèves doivent s’organiser pour :\n\nClarifier le bilan des travaux fait dans la semaine (partie « bilan » de la fiche de suivi) ;\nFaire une relecture de code (lors de la phase de développement) ;\nAffecter un numéro de version au code qui servira à l’échange, code qui doit se trouver sur le dépôt git ET être exécutable (lors de la phase de développement).\n\nA chaque séance, l’encadrant notera si un travail sérieux a été réalisé depuis la semaine dernière. Un travail régulier tout le long du projet sera récompensé, tandis qu’un travail fait uniquement avant les rendus sera pénalisé.\nLes séances de suivi sont obligatoires. L’appel sera effectué en début et en fin de séance. Votre intervenant pourra demander à tout moment à parler avec la totalité des élèves qu’il encadre. 1 ### Fiche de temps Une fiche de temps synthétique disponible sur Moodle est à compléter chaque semaine et vous sera demandée après la soutenance. Cette fiche de temps vise principalement à mieux calibrer la charge du projet informatique d’une année sur l’autre. Elle n’impacte pas l’évaluation du groupe. Pour information, le projet informatique vous permet d’obtenir 4 ECTS, ce qui représente un investissement d’environ 100h (séances en présentiel comprises) par élève.\nElle peut aussi vous aider à objectiver l’investissement de chacun dans le projet, mais il faut garder à l’esprit que cette fiche ne permet de visualiser que des apports quantifiables (heures de travail et ligne de code), alors que les apports de chacun peuvent être bien plus divers : animation du groupe, conseils, expertise… 1 ### Première séance De retour d’étudiants, la première rencontre du groupe est importante. C’est l’occasion pour vous de faire connaissance et d’échanger honnêtement sur vos capacités et ce que vous attendez du projet. Les groupes qui ont un bon fonctionnement sont ceux qui réussissent le mieux. Comme il n’y a pas de recette magique, chaque groupe doit se mettre d’accord sur son fonctionnement. 1 ### Le chef de projet Au sein de chaque groupe, les élèves devront désigner un chef de projet qui sera responsable de l’animation du groupe et qui organisera les réunions de travail. Il sera également responsable de la répartition et du suivi de l’avancement du travail. Il pourra, pour l’aider dans cette tâche, utiliser la fiche de suivi (voir Moodle). Il devra également veiller au respect du planning général. Il est l’interlocuteur privilégié de l’encadrant pour le groupe qu’il représente. Il doit permettre la discussion et la prise de décision collégiale.\nCe rôle n’a pas être lié aux compétences informatiques, mais à l’appétence pour la gestion d’équipe. Ce rôle pourra être valorisé dans le rapport individuel. 1 ### Lien avec le module de Compléments d’informatique Pour vous aider à mener à bien votre projet, un cours de 6h, et quatre TP de 3h sont mis en place dans le module de Compléments d’informatique. Lors du cours, vous seront présentés l’organisation générale du projet et quelques concepts nouveaux (systèmes de versionnement (git), appel à une base de données depuis un programme, liens entre données dans un programme et dans une base de données, formats No-SQL, …). Lors des TP ces concepts seront mis en œuvre.\nBien que ce cours a pour utilité directe de vous aider à mener à bien votre projet, il a pour but final de vous donner des connaissances supplémentaires en informatique pour que vous puissiez évoluer facilement dans le monde de la data science. 1 ### Outils de développement Les outils de développement à votre disposition seront :\n\nL’environnement de développement Visual Studio Code disponible sur votre VM;\nLe logiciel de partage de code et versionnement Git, accessible depuis l’environnement de développement, accompagné d’un dépôt (privé) que vous devrez créer sur un serveur public (GitLab, Github, Bitbucket) ;\nUne base de données PostgreSQL (hébergée à l’Ensai) comme système de gestion de base de données (SGBD) pour la persistance des données. Vous utiliserez l’environnement d’un élève sur la base de l’Ensai pour votre projet ;\nUn certain nombre de librairies et outils pour le lien entre Python et le SGBD, les tests unitaires, la génération automatique de documentations, …\n\npsycopg2 pour se connecter à la base postgreSQL, https://www.psycopg.org/docs/\nrequests pour réaliser des requêtes http, https://requests.readthedocs.io/en/master/\nunittest pour les tests unitaires, https://docs.python.org/fr/3/library/unittest.html\npydoc pour la documentation, https://docs.python.org/fr/3/library/pydoc.html\nabc pour les classes abstraites, https://docs.python.org/fr/3/library/abc.html\nflask-restful pour la création d’un webservice REST :\nhttps://flask-restful.readthedocs.io/en/latest/index.html\nfastAPI pour la création d’un webservice REST :\nhttps://fastapi.tiangolo.com/\n\n\nEn plus de cette liste, vous êtes libre d’utiliser les outils de votre choix, à condition d’être capable de les utiliser sans demander de l’aide inutilement.\nRemarque : demander de l’aide est normal et fait partie de l’apprentissage. Nous ne notons pas quels sont les groupes qui nous demandent de l’aide. Faire preuve d’autonomie ne veut pas dire travailler sans demander de l’aide. Si vous rencontrez une difficulté, qu’après plusieurs tentatives vous ne trouvez pas de solution et que vous demandez finalement de l’aide pour la résoudre, vous êtes autonome. Si par contre vous attendez que le problème disparaisse ou que l’on vienne vous aider, là vous manquez d’autonomie. Soyez proactif dans votre démarche. Vous progresserez bien plus vite. 1 ### Outils de gestion de projet et de communication Je vous recommande fortement d’utiliser Microsoft Teams pour planifier vos travaux et échanger. Le création d’une conversation pour le groupe me semble le minimal. Mais vous pouvez également installer des plugins pour vous aider à gérer votre projet. Voici quelques propositions\n\nTrello : pour avoir un kanban collaboratif ;\nPriority Matrix : pour prioriser vos tâches ;\n\nVous pouvez également utiliser d’autres logiciels pour communiquer, comme Slack ou Discord (qui sont propriétaires comme Teams). Je vous déconseille d’utiliser Facebook Messenger ou autres applications liées à un réseau social qui ne sont pas utilisées pour gérer un projet en entreprise. La limites de ces logiciels de messagerie est qu’ils ne proposent pas de salon de discussions thématiques pour segmenter vos échanges. Cela entraine de la perte d’informations quand plusieurs discussions se mélangent.\nPour les personnes qui ont du mal à s’organiser mais qui sont sensible à la gamification vous pouvez également utiliser Habitica (https://habitica.com/static/home) pour vous aider à travailler régulièrement. 1. ## Description du travail attendu 1 ### Processus de développement Le développement s’effectuera collectivement et en cascade. Les phases d’étude préalable, de conception générale, de réalisation et de validation s’enchaînent successivement dans le temps. 1 ### Étude préalable Cette 1 phase d’analyse consiste en la formalisation des besoins décrits par le cahier des charges (le sujet, le point de vue du demandeur ou du maître d’ouvrage). Elle devra permettre d’établir :\n\nLe périmètre du système d’information cible en reprécisant les aspects du sujet qui peuvent apparaître flous ;\nLes besoins à satisfaire par le système d’information cible (cas d’utilisation et description des menus) ;\nLes exigences particulières et les contraintes (normes de développement, architecture). 1 ### Conception générale du logiciel Cette 2 phase d’analyse aboutira à un modèle de conception pour répondre aux objectifs fixés par le cahier des charges. Le choix des diagrammes est fait par chaque groupe après validation de leur intervenant. On y trouvera cependant au minimum :\nUn diagramme de cas d’utilisation ;\nUn diagramme de classes ;\nUn modèle physique de données.\n\nEn fonction de votre sujet et de ce que vous demande votre intervenant vous pourrez y ajouter :\n\nUn diagramme de d’activité ou d’état ;\nUn diagramme de séquence ;\nUn modèle logique de données (diagramme entité-relation) ;\n\nLes sujets et les encadrants sont différents, alors préférez faire des choses cohérentes avec ses attendus, que simplement cocher des cases.\nRemarque : si certains diagrammes ne vous disent rien, il y a plusieurs livres sur la modélisation UML à la bibliothèque. 1 ### Réalisation et Validation du logiciel #### La base de données L’application s’appuiera sur une base de données, que vous devez créer. Pour vous sensibiliser à la variété des données, votre travail devra comporter l’importation ou l’exportation d’un jeu de données. Ce jeu de données sera fourni par l’encadrant dans le format de son choix (XML, JSON, CSV …). #### Codage de l’application L’application sera réalisée en Python. Le code sera naturellement cohérent avec les diagrammes du modèle de conception déjà établis. Si nécessaire, ces derniers seront mis à jour afin que cette cohérence soit maintenue. Il n’y a pas d’interface graphique à développer, la communication avec l’application se faisant par l’intermédiaire de la console ou d’un webservice. Toutes les fonctionnalités de votre application doivent pouvoir être testées et démontrées via la console ou des requêtes http. #### Validation du logiciel Tout au long du développement, vous développerez un ensemble de tests :\n\nTests unitaires (pour une classe métier au minimum) ;\nTests utilisateurs pour chaque cas d’utilisation important.\n\nÀ la différence des autres années, votre tuteur sélectionnera une classe que vous devrez tester entièrement. #### Livraison du dossier d’analyse (Au format électronique uniquement, sur Moodle)\nCe premier livrable est l’aboutissement de la phase d’étude préalable et de conception générale. Il doit montrer que vous avez compris votre sujet et que vous avez une première modélisation de votre application. Ainsi cette livraison contiendra :\n\nUn planning détaillé des 3 phases décrites ci-dessus (diagramme de Gantt incluant un volume horaire prévu pour chaque tâche) ;\nLes diagrammes réalisés pendant la phase d’analyse (voir section Conception générale du logiciel) ;\nUn document d’architecture spécifiant l’organisation logique des sous-systèmes techniques (paquetages métier, persistance) ;\nLes principaux menus de l’application et leurs enchainements si cela a du sens ;\nLes principaux endpoints de votre application si cela a du sens :\nUne description des fonctionnalités de votre application ;\nUne liste des composants à implémenter ainsi que :\n\nLeur rôle ;\nLa description de leurs dépendances réciproques ;\nLe temps de développement prévu pour chacun d’entre eux ;\nL’ordre de priorité initiale ;\n\n\nUne taille raisonnable pour ce livrable est de 10 à 15 pages, annexes comprises. Vous pouvez faire plus long mais dans ce cas posez-vous la question : « Ce que j’ajoute est-il nécessaire ? ». Il n’est pas obligatoirement rédigé en LaTeX mais doit-être « propre ». Il sera noté par votre intervenant qui vous en fera un retour. 1 ### Livraison finale collective (Au format électronique uniquement, sur Moodle)\nLa livraison finale du projet est l’aboutissement de 3 mois de travail et doit décrire et valoriser le travail produit. Elle contiendra : #### Un rapport de fin de projet Votre rapport final doit présenter le travail réalisé pendant ces 3 mois. Voici les éléments qu’il devra contenir :\n\nLe contexte de votre application. Cette partie doit permettre à une personne externe à votre projet et sans expérience particulière en informatique de comprendre l’intérêt de votre travail. Ainsi, il vous est conseillé de faire relire cette partie par une personne externe à votre groupe (ami, famille). La rédaction de cette partie peut commencer très tôt car elle ne repose pas sur des éléments techniques que vous allez implémenter.\n\nÀ quels besoins répond-elle ? Le diagramme de cas d’utilisation n’est pas nécessaire dans le rapport final ;\nQuels sont les utilisateurs de l’application ?\nQuelles sont les données intéressantes de votre application. Si vous utilisez des données externes présentez leur source, le format, et les concepts associés. Si vous en produisez, présentez le format des données et comment elles peuvent être utilisées. Par exemple :\n\nVous récupérez des annonces immobilières via webscrapping, quel est le site ou quels sont les sites utilisés ? Quelles données récupérées vous de la page ? Vous pourrez décrire plus tard comment vous les récupérez ;\nVous devez traiter des données géographiques, comment sont stockées vos données dans votre source ? Il y-a-t-il des difficultés particulières dans ces données ?\nVous récupérez des données d’un service externe, quel est le schéma de ces données ?\n\nL’architecture générale de votre application\n\nEst-ce un module python ? Un script sans interaction avec l’utilisateur ? Une application en console ? Une application avec un client et un serveur qui communiquent via requête http ?\nLes technologies nécessaires à son fonctionnement (python, bibliothèques majeures utilisées, système de persistance, sources de données externes)\nUn schéma d’architecture (pour faire le lien entre les différents composants de votre application comme votre code, système de persistance, etc.)\n\n\nComment votre application permet de répondre aux besoins que vous avez décrits :\n\nLe fonctionnement votre application :\n\nZoom sur un processus central en le détaillant complètement pour que le jury comprenne la logique que vous avez mis en place. Qu’est-ce que l’utilisateur fait ? Qu’est-ce que votre produit fait ? Comment interagit-il avec les autres composants ? Quelles sont les classes utilisées ? Il n’est pas utile de préciser les méthodes appelées, sauf si vous pensez que cela a un intérêt. Pour aider le lecteur, vous pouvez ajouter des diagrammes de cas d’utilisations, mais aussi des schémas divers ;\nExplication rapide pour les autres. Votre rapport ne doit pas être un listing des fonctions pythons de votre application ;\n\n\n\nPrivilégiez la qualité des explications à la quantité. Si vous décrivez sérieusement une fonctionnalité centrale intéressante, le jury supposera que vous êtes capable de faire la même chose pour les autres. Vous pouvez illustrer vos propos en utilisant votre diagramme de classe. Cela vous permet :\n\nD’expliquer les héritages/associations utilisés ;\nDe présenter les objets métiers et comment ils sont utilisés par l’application ;\nDe mettre en avant une décomposition en couche, un découplage entre les objets ;\n\nRemarque : un diagramme de classe n’est pas une finalité en soit, il est initialement produit pour servir de boussole lors de l’implémentation de votre application. De la même manière, dans votre rapport il doit servir à guider vos explications. Ainsi, il n’est pas nécessaire de produire un diagramme de classe unique si celui-ci est illisible. Vous pouvez le décomposer en petits diagrammes qui vont se concentrer sur des fonctionnalités particulières. De même, il est fortement déconseillé de lister et décrire exhaustivement toutes les classes et les méthodes.\n\nPrésentation du système de stockage, à quels moments il est utilisé dans votre application et pourquoi ? Vous pouvez mettre en avant l’utilisation de formes normales. En effet ce projet doit vous permettre de mettre en avant vos acquis de 1A en la matière. Il est inutile de nous présenter l’intégralité de vos DAOs ;\nLes outils mis en place pour réaliser le projet :\n\nL’organisation que vous avez choisie dans votre groupe ;\nLes outils mis en place et leur utilisation ;\nLa démarche d’assurance qualité. Le but de cette partie est de montrer que vous avez pris en compte les évènements extérieurs qui peuvent impacter votre application.\n\nAvez-vous fait des tests ? Pourquoi avez-vous testé ces classes en particulier ? Qu’est-ce que cela vous a apporté ?\nAvez-vous rencontré des temps de traitement longs ? D’où viennent-ils ? Les avez-vous surmontés ?\nSi votre source de données venait à disparaitre mais qu’une nouvelle source similaire existait, comment cela impacterait-il votre application ?\nSi vous avez mis de côté des fonctionnalités au cours de votre développement, comment peuvent-elles être mis en place dans le futur ? #### Le code de votre application\n\n\nLes requêtes SQL permettant la création des tables et du jeu de données de test dans un fichier init_db.sql. Ces requêtes ne doivent pas figurer dans votre rapport ;\nLe code source complet de l’application, dont :\n\nUn fichier main.py qui permet de lancer votre application ;\nUne classe commentée choisie par votre tuteur ;\nDes tests unitaires pour une classe choisie par votre tuteur ;\nUne fichier README.md à la racine du projet présentant votre projet. Cette page sera rédigée en anglais et devra :\n\nPrésenter rapidement votre application (but) avec quelques exemples\nExpliquer comment l’installer\n\nUn fichier requirements.txt avec tous les modules pythons à installer pour faire fonctionner votre application.\n\n\nBien entendu, cette liste ne définit que les composantes minimales de votre rendu. Chaque groupe de projet est libre de fournir toutes les informations complémentaires qui lui parait pertinentes pour mettre en avant son travail. Cela peut-être : expliquer des choix de conceptions qui vous semblent pertinents, des outils que vous avez utilisés ou tout autres informations qui vous permet de valoriser votre travail. Vous avez le droit d’illustrer vos propos avec des figures pour aider le lecteur. Les images qui n’apportent rien à votre propos sont à proscrire. L’ordre de présentation des différents points, et de leur classement en annexe est libre. La taille optimale de ce rapport est de 25 pages hors annexe. Vous pouvez faire plus long mais dans ce cas posez-vous la question : « Ce que j’ajoute est-il nécessaire ? ». Il n’est pas obligatoire de le rédiger en LaTeX. Enfin, un minimum de rigueur est attendu de futurs ingénieurs. Un nombre limité de coquilles dans votre production est toléré, par contre si cela nuit à la compréhension de votre rapport vous serez sanctionnés.\nRemarque : dans le cas où vous rédigez votre rapport en LaTeX, faites attention au placement des images. Certains d’entre vous usent et abusent du package float et l’option [H] pour fixer les images. Cela entraine de gros espaces laissés blancs dans vos rapports et donne une mauvaise impression au lecteur. Privilégier l’option [htb]. Le placement sera moins précis, mais limitera ces zones blanches.\nPendant le temps entre ce rendu et la soutenance vous avez le droit de modifier votre code, mais ces modifications ne devront être là uniquement pour améliorer la qualité de la démonstration car ce nouveau code ne sera jamais livré pour notation. 1 ### Livraison finale individuelle Lors du rendu du rapport chaque élève de chaque groupe joindra une note décrivant son expérience au sein du groupe de projet. Cette note devra être insérée dans le rapport final en fin de rapport. Dans cette note d’une à deux pages, vous relaterez aussi bien les bonnes pratiques mises en œuvre que les problèmes rencontrés. Vous pouvez adopter un style moins formel que pour le rapport, mais garder en tête que cette note est lue par le jury au même titre que le reste du rapport. Conserver une mise en page correcte pour cette note. Pour vous aider voici des éléments qui ont leur place dans cette note :\n\nVotre participation effective au projet (chef de projet, code, animation, etc.)\nComment avez-vous vécu le projet avec votre groupe. Est-ce difficile ? Enrichissant ? Eviter les lieux communs, et préférez utilisez des exemples concrets. Vous pouvez mettre en avant des points de tensions qui se sont produits.\nLes enseignements que vous en tirez, ce que vous referiez, ce que vous changerez. Vous pouvez construire cette partie comme une des conseils que vous donnez à vos successeurs.\n\nNous vous conseillons la relecture de cette production individuelle par une autre personne (membre du groupe, ami, famille) pour limiter les fautes et ainsi vous assurer qu’elle est compréhensible. Cette note personnelle est très appréciée par les membres du jury, faites-la sérieusement et honnêtement. 1 ### La soutenance Vous présenterez votre travail devant un jury de 3 personnes : un président de jury, qui est un professionnel de l’informatique (du secteur public ou privé), votre encadrant, et un représentant de l’Ensai. La soutenance consistera en une présentation orale de votre logiciel, partagée équitablement entre les membres du groupe. Elle fera apparaître la méthode de développement utilisée, les choix et options de conception et de programmation retenues. Cette présentation durera 20 minutes, dont 12 minutes environ devront être consacrées à une présentation type diaporama (Beamer ou autre) et 8 minutes à la démonstration de l’application. L’organisation du temps est libre mais doit être dynamique.\nSuivra une séance de questions du jury d’environ 15 minutes. Puis 5 minutes de retours du jury après délibération.\nLe jury est bienveillant et ne cherchera pas à vous piéger !\nQuelques conseils pour cette soutenance :\n\nPrésentez brièvement les membres du groupe ;\nMême si les membres du jury ont lu votre rapport, prenez le temps de présenter sommairement le besoin initial et les données impliquées s’il y en a ;\nÉvitez les présentations catalogues du type : « On a fait ça, ça et aussi ça ». Le jury déteste, surtout quand c’est le 4e groupe de suite qui raconte la même chose. Soyez un minimum original, prenez un angle décalé, racontez une histoire !\nPrésentez la plus-value du groupe :\n\nAvez-vous fait des choix forts ?\nAvez-vous mis en place un processus intéressant ?\nRépondez-vous au besoin ?\n\nIl n’est pas nécessaire de suivre le même déroulé que le rapport, ni de représenter le rapport (le jury l’a lu). Par exemple, si vous avez expliqué rapidement une fonctionnalité dans le rapport mais qu’elle vous semble intéressante, vous pouvez la détailler plus lors de la soutenance. Le jury aime la nouveauté.\nMettez en avant le projet (comment avez-vous travaillé ces 3 mois) et pas seulement le logiciel produit (vous n’essayez pas de nous vendre votre application). Cela peut passer par une analyse Strenghts – Weaknesses – Opportunities – Threats de votre groupe ;\nVous pouvez mélanger chronologiquement la présentation et la démo ;\nIllustrez vos transparents avec des schémas / graphiques / captures d’écran / … Faites attention que vos images soient lisible une fois projetées. Mais ne mettez pas des illustrations inutiles. Si un diaporama illustré est agréable si les images utilisées aident à la compréhension, un trop plein d’images sans rapport avec le propos nuisent à la compréhension.\nNe mettez pas de code, mais du pseudo-code (et uniquement si l’algorithme est intéressant).\nTravaillez votre introduction et votre conclusion. 1 ### Notation finale La note finale du projet se répartit comme suit :\nDossier d’analyse et investissement dans le projet (1/3) ;\nRapport final et investissement dans le projet (1/3) ;\nSoutenance (1/3).\n\nLe code est noté à part. Cette note est prise en compte par le module Compléments d’informatique.\nSi le travail ou l’implication d’un ou plusieurs membres du groupe étaient en deçà des attentes, leurs notes pourraient être dissociées de celle du reste du groupe. Cela ne sera possible qu’après avoir alerté votre tuteur et le référent de la matière et qu’une discussion avec le groupe n’a eu lieu. À l’inverse, les membres moteurs du groupe pourront être favorisés.\nVous trouverez sur Moodle les grilles de notation qui sont fournies aux intervenants, pour évaluer votre travail, cette annexe a un rôle de sensibilisation et ne constitue pas un barème définitif. 1. ## Calendrier\n\n\n\n\n\n\n\n1 septembre\nTP + suivi de projet\n\n\n\n\n8 septembre\nTP + suivi de projet\n\n\n15 septembre\nTP\n\n\n29 septembre\nTP + suivi de projet\n\n\n7 octobre 12h00\nRemise du dossier d’analyse\n\n\n13 octobre\nSuivi de projet\n\n\n25-27 octobre\n3 jours d’immersion avec suivi le premier et dernier jour\n\n\n17 novembre\nSuivi de projet\n\n\n25 novembre 23h59\nRemise du rapport final\n\n\n12 décembre\nSoutenance\n\n\n\nLes 26, 27 et 28 octobre aura lieu une période d’immersion. Pendant ces 3 jours, vous n’aurez pas cours et pourrez avancer votre projet. Vous êtes libre de vous organiser comme bon vous semble sur ces 3 jours, selon que vous soyez lève tôt ou lève tard. Cependant, ces 3 jours ne sont pas facultatifs et ne sont pas faits pour vous permettre de récupérer d’une soirée ou pour partir plus tôt en week-end. Votre présence sera contrôlée.\nÀ la fin de ces 3 jours, avec un travail sérieux et efficace, vous devriez avoir bien avancé la phase de code (&gt; 80 %) et commencé le squelette du rapport final. Ainsi, vous serez beaucoup plus sereins pour attaquer la dernière ligne droite en novembre.\nVous verrez votre tuteur le premier jour pour qu’il vous aide à prioriser vos travaux, et le dernier pour vous aider. Une démonstration, même limitée, de votre application sera demandée le vendredi. Page 1** sur 12**"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projet informatique 2e année",
    "section": "",
    "text": "Tous les élèves de deuxième année participent à la réalisation du projet informatique par groupes de 4 ou 5 élèves.\nCe projet permet d’effectuer un approfondissement et une mise en pratique des connaissances acquises lors des enseignements informatiques de 1ère année.\nLe travail demandé consiste à construire une application permettant de répondre à la problématique d’un sujet proposé. Ce travail se décompose en 2 grandes phases :\n\nÉtude préalable et Conception générale de l’application\n\n\ndécrire la solution envisagée\nplanifier les grandes phases de la réalisation\ndécrire les exigences fonctionnelles par la modélisation\n\n\nRéalisation\n\n\nmise en place de la base de données\ndéveloppements, tests, documentation"
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "Projet informatique 2e année",
    "section": "",
    "text": "Tous les élèves de deuxième année participent à la réalisation du projet informatique par groupes de 4 ou 5 élèves.\nCe projet permet d’effectuer un approfondissement et une mise en pratique des connaissances acquises lors des enseignements informatiques de 1ère année.\nLe travail demandé consiste à construire une application permettant de répondre à la problématique d’un sujet proposé. Ce travail se décompose en 2 grandes phases :\n\nÉtude préalable et Conception générale de l’application\n\n\ndécrire la solution envisagée\nplanifier les grandes phases de la réalisation\ndécrire les exigences fonctionnelles par la modélisation\n\n\nRéalisation\n\n\nmise en place de la base de données\ndéveloppements, tests, documentation"
  },
  {
    "objectID": "index.html#présentations",
    "href": "index.html#présentations",
    "title": "Projet informatique 2e année",
    "section": "Présentations",
    "text": "Présentations\n\nPrésentation du projet aux tutrices et tuteurs\nNotice élèves"
  },
  {
    "objectID": "doc/stage-slide.html#objectifs",
    "href": "doc/stage-slide.html#objectifs",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Objectifs",
    "text": "Objectifs\n\nDévelopper une application en python\nDécouvrir l’architecture logicielle\nCommuniquer avec une base de données PostreSQL\nUtiliser des webservices\nConcevoir et Modéliser"
  },
  {
    "objectID": "doc/stage-slide.html#compétences-visées",
    "href": "doc/stage-slide.html#compétences-visées",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Compétences visées",
    "text": "Compétences visées\n\nTravailler en groupe (kanban, git)\nModéliser une application complexe (UML)\nAppliquer les principes de la POO\nValoriser son travail à l’écrit et à l’oral"
  },
  {
    "objectID": "doc/stage-slide.html#cours",
    "href": "doc/stage-slide.html#cours",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Cours",
    "text": "Cours\nLe cours de compléments d’informatique vise à fournir aux élèves les outils pour mener à bien le projet informatique.\n\n6h des cours\n4 TP de 3h\n\ndispensés par les tutrices / tuteurs\nle sujet est fourni"
  },
  {
    "objectID": "doc/stage-slide.html#cadre-général-du-projet",
    "href": "doc/stage-slide.html#cadre-général-du-projet",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Cadre général du projet",
    "text": "Cadre général du projet\n\n1er semestre de 2A\nGroupes imposés de 4 ou 5 élèves\nLes groupes votent pour leurs sujets préférés\n4 groupes par tuteur"
  },
  {
    "objectID": "doc/stage-slide.html#phases",
    "href": "doc/stage-slide.html#phases",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "2 phases",
    "text": "2 phases\n\nAnalyse / Conception générale (sept)\n\n4 séances de 3h de suivi\nla séance de mi-octobre permet de faire un retour aux équipes sur le dossier d’analyse\n\nImplémentation (oct-nov)\n\n3 séances de 3h de suivi"
  },
  {
    "objectID": "doc/stage-slide.html#livrables",
    "href": "doc/stage-slide.html#livrables",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Livrables",
    "text": "Livrables\n\n5 octobre : Dossier d’analyse\n23 novembre : Rapport final + code\n3 décembre : Soutenance"
  },
  {
    "objectID": "doc/stage-slide.html#planning-prévisionnel",
    "href": "doc/stage-slide.html#planning-prévisionnel",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Planning prévisionnel",
    "text": "Planning prévisionnel\n\n\n\n\n\n\ngantt\n    title Planning provisoire 2024\n    dateFormat  YYYY-MM-DD\n    axisFormat  %d %b\n    tickInterval 1week\n    \n    section Cours\n    CM                           :milestone, 2024-09-04,\n    CM                           :milestone, 2024-09-18, \n    Examen                       :milestone, 2024-10-15,\n    \n    section TP\n    TP1                          :milestone, 2024-09-06,\n    TP2                          :milestone, 2024-09-13,\n    TP3                          :milestone, 2024-09-20,\n    TP4                          :milestone, 2024-09-27,\n    \n    section Projet\n    Suivi 1                      :milestone, 2024-09-06,\n    Suivi 2                      :milestone, 2024-09-13,\n    Suivi 3                      :milestone, 2024-09-27,\n    Suivi 4                      :milestone, 2024-10-11,\n    3j immersion (Suivi 5 et 6)  :active,    2024-10-21, 3d\n    Suivi 7                      :milestone, 2024-11-15,\n    \n    section Échéances\n    WEI                          :crit,      2024-09-20, 3d\n    Dossier Analyse              :milestone, 2024-10-05,\n    Toussaint                    :crit,      2024-10-26, 2024-11-03\n    Rapport final et Code        :milestone, 2024-11-23,\n    Soutenance                   :milestone, 2024-12-03,\n    \n    %%Stats univariées retraités   :done,         2021-11-28, 3d"
  },
  {
    "objectID": "doc/stage-slide.html#sujet",
    "href": "doc/stage-slide.html#sujet",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Sujet",
    "text": "Sujet\nÀ vous de jouer pour trouver une bonne idée !"
  },
  {
    "objectID": "doc/stage-slide.html#résumé-du-travail-de-tutrice-tuteur",
    "href": "doc/stage-slide.html#résumé-du-travail-de-tutrice-tuteur",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Résumé du travail de tutrice / tuteur",
    "text": "Résumé du travail de tutrice / tuteur\n\n4 x 3h de TP de compléments d’informatique\n7 x 3h de suivi de projet\nLire et noter les 4 dossiers d’analyse\nNoter le code\nLire du rapport final, participer à la notation\nParticiper aux 4 soutenances"
  },
  {
    "objectID": "doc/stage-slide.html#points-à-préciser",
    "href": "doc/stage-slide.html#points-à-préciser",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Points à préciser",
    "text": "Points à préciser\n\nIdée pour suivre le projet\n\npoint hebdo : tout le monde doit envoyer son point hebdo chaque vendredi soir\nKanban (GitHub project)\n\nCI/CD basique (TU, cov, pylint)\ninclure l’utilisation de logs\n\n\n\n\nHome — Présentation aux tutrices et tuteurs"
  },
  {
    "objectID": "doc/presentation-tuteurs.html",
    "href": "doc/presentation-tuteurs.html",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "",
    "text": "Développer une application en python\nDécouvrir l’architecture logicielle\nCommuniquer avec une base de données PostreSQL\nUtiliser des webservices\nConcevoir et Modéliser"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#objectifs",
    "href": "doc/presentation-tuteurs.html#objectifs",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "",
    "text": "Développer une application en python\nDécouvrir l’architecture logicielle\nCommuniquer avec une base de données PostreSQL\nUtiliser des webservices\nConcevoir et Modéliser"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#compétences-visées",
    "href": "doc/presentation-tuteurs.html#compétences-visées",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Compétences visées",
    "text": "Compétences visées\n\nTravailler en groupe (kanban, git)\nModéliser une application complexe (UML)\nAppliquer les principes de la POO\nValoriser son travail à l’écrit et à l’oral"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#cours",
    "href": "doc/presentation-tuteurs.html#cours",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Cours",
    "text": "Cours\nLe cours de compléments d’informatique vise à fournir aux élèves les outils pour mener à bien le projet informatique.\n\n6h des cours\n4 TP de 3h\n\ndispensés par les tutrices / tuteurs\nle sujet est fourni\n\n\n\nNotions abordées en cours\n\nUtilisation basique de Git\nRappels de POO\nDécomposer une application en couches\nCommuniquer avec une base de données / une API\nTests unitaires\nDocumentation"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#cadre-général-du-projet",
    "href": "doc/presentation-tuteurs.html#cadre-général-du-projet",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Cadre général du projet",
    "text": "Cadre général du projet\n\n1er semestre de 2A\nGroupes imposés de 4 ou 5 élèves\nLes groupes votent pour leurs sujets préférés\n4 groupes par tuteur"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#phases",
    "href": "doc/presentation-tuteurs.html#phases",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "2 phases",
    "text": "2 phases\n\nAnalyse / Conception générale (sept)\n\n4 séances de 3h de suivi\nla séance de mi-octobre permet de faire un retour aux équipes sur le dossier d’analyse\n\nImplémentation (oct-nov)\n\n3 séances de 3h de suivi"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#livrables",
    "href": "doc/presentation-tuteurs.html#livrables",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Livrables",
    "text": "Livrables\n\n5 octobre : Dossier d’analyse\n23 novembre : Rapport final + code\n3 décembre : Soutenance\n\n\nDossier d’analyse\nDocument d’une dizaine de pages contenant :\n\nla compréhension du besoin\nun planning (diagramme de Gantt)\ndes diagrammes UML (cas d’utilisation, classe…)\n\n\n\nSoutenance\nLes soutenances ont lieu début décembre.\nLes élèves présentent leur projet à un jury composé de 3 personnes :\n\nun président de jury\nun enseignant de l’ENSAI\nla tutrice / le tuteur\n\n\n\nNotes\n\n\n\nLivrable\nCorrecteur\nCoef projet\nCoef cours\n\n\n\n\nDossier d’analyse\nTutrice / Tuteur\n1/3\n\n\n\nCode\nTutrice / Tuteur\n\n1/2\n\n\nRapport final\nJury\n1/3\n\n\n\nSoutenance\nJury\n1/3\n\n\n\nDevoir sur table\nEnseignant\n\n1/2\n\n\n\nLe code du projet comptera pour 50% de la note du cours de Compléments d’informatique."
  },
  {
    "objectID": "doc/presentation-tuteurs.html#planning-prévisionnel",
    "href": "doc/presentation-tuteurs.html#planning-prévisionnel",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Planning prévisionnel",
    "text": "Planning prévisionnel\n\n\n\n\n\n\ngantt\n    title Planning provisoire 2024\n    dateFormat  YYYY-MM-DD\n    axisFormat  %d %b\n    tickInterval 1week\n    \n    section Cours\n    CM                           :milestone, 2024-09-04,\n    CM                           :milestone, 2024-09-18, \n    Examen                       :milestone, 2024-10-15,\n    \n    section TP\n    TP1                          :milestone, 2024-09-06,\n    TP2                          :milestone, 2024-09-13,\n    TP3                          :milestone, 2024-09-20,\n    TP4                          :milestone, 2024-09-27,\n    \n    section Projet\n    Suivi 1                      :milestone, 2024-09-06,\n    Suivi 2                      :milestone, 2024-09-13,\n    Suivi 3                      :milestone, 2024-09-27,\n    Suivi 4                      :milestone, 2024-10-11,\n    3j immersion (Suivi 5 et 6)  :active,    2024-10-21, 3d\n    Suivi 7                      :milestone, 2024-11-15,\n    \n    section Échéances\n    WEI                          :crit,      2024-09-20, 3d\n    Dossier Analyse              :milestone, 2024-10-05,\n    Toussaint                    :crit,      2024-10-26, 2024-11-03\n    Rapport final et Code        :milestone, 2024-11-23,\n    Soutenance                   :milestone, 2024-12-03,\n    \n    %%Stats univariées retraités   :done,         2021-11-28, 3d"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#sujet",
    "href": "doc/presentation-tuteurs.html#sujet",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Sujet",
    "text": "Sujet\nÀ vous de jouer pour trouver une bonne idée !\n\nÉléments requis\n\nUtilisation de la POO\nStockage en BDD (sans utiliser d’ORM type SQLAlchemy)\nUtilisation et / ou Création d’un webservice\nPas d’interface graphique\n\npour les sujets n’impliquant pas de création de WS, InquirerPy sera utilisé comme IHM en mode console\n\n\n\n\nExemples de sujets\n\nApplication utile\n\ndonnées SNCF pour optimiser ses réductions\nréduire l’impact carbone de la VOD\nrecherche de stage, de velib, de carburant moins cher, de bières\nrecommandation de produits meilleurs pour la santé\n\nAutour des jeux ou de la musique\n\nstats de jeux videos\nJeux de mots (Wordle)\nconvention de JDR\nRAP analytics\n\n\nIl est tout à fait possible de proposer un sujet plus exotique (⚠️ à ne pas trop faire peur aux élèves).\n\n\nAnciens sujets\nListe des anciens sujets.\n\n\nTemplate\n\n### Titre\n\nTuteur / Tutrice : \n\n#### Présentation\n\ncontexte, objectifs, API utilisée, création d'une API et/ou d'un menu interactif ?\n\n#### Fonctionnalités de base\n\n- F1 : \n- F2 : \n\n#### Fonctionnalités optionnelles\n\n- FO1 : \n- FO2 : \n\n#### Conseils / Outils ..."
  },
  {
    "objectID": "doc/presentation-tuteurs.html#résumé-du-travail-de-tutrice-tuteur",
    "href": "doc/presentation-tuteurs.html#résumé-du-travail-de-tutrice-tuteur",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Résumé du travail de tutrice / tuteur",
    "text": "Résumé du travail de tutrice / tuteur\n\n4 x 3h de TP de compléments d’informatique\n7 x 3h de suivi de projet\nLire et noter les 4 dossiers d’analyse\nNoter le code\nLire du rapport final, participer à la notation\nParticiper aux 4 soutenances"
  },
  {
    "objectID": "doc/presentation-tuteurs.html#points-à-préciser",
    "href": "doc/presentation-tuteurs.html#points-à-préciser",
    "title": "Présentation aux tutrices et tuteurs",
    "section": "Points à préciser",
    "text": "Points à préciser\n\nIdée pour suivre le projet\n\npoint hebdo : tout le monde doit envoyer son point hebdo chaque vendredi soir\nKanban (GitHub project)\n\nCI/CD basique (TU, cov, pylint)\ninclure l’utilisation de logs"
  }
]